# íŒŒì¼ëª… ì˜ˆì‹œ: saju_app.py
# ì‹¤í–‰: streamlit run saju_app.py
# í•„ìš” íŒ¨í‚¤ì§€: pip install streamlit pandas openpyxl lunardate

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import os
import math
import re # HTML íƒœê·¸ ì œê±°ë¥¼ ìœ„í•´ ì¶”ê°€

# --- ìŒë ¥ ë³€í™˜ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
try:
    from lunardate import LunarDate
except ImportError:
    st.error("ìŒë ¥ ë³€í™˜ì„ ìœ„í•œ 'lunardate' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í„°ë¯¸ë„ì—ì„œ `pip install lunardate`ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# -------------------------------
# HTML íƒœê·¸ ì œê±° í—¬í¼ í•¨ìˆ˜
# -------------------------------
def strip_html_tags(html_string):
    if not isinstance(html_string, str):
        return str(html_string)
    # Remove style blocks
    html_string = re.sub(r'<style.*?</style>', '', html_string, flags=re.DOTALL | re.IGNORECASE)
    # Remove script blocks
    html_string = re.sub(r'<script.*?</script>', '', html_string, flags=re.DOTALL | re.IGNORECASE)
    # Remove all other HTML tags
    clean_text = re.sub(r'<[^>]+>', '', html_string)
    # Replace common HTML entities
    clean_text = clean_text.replace('&nbsp;', ' ')
    clean_text = clean_text.replace('&lt;', '<')
    clean_text = clean_text.replace('&gt;', '>')
    clean_text = clean_text.replace('&amp;', '&')
    # Remove excessive newlines and whitespace, keep meaningful newlines
    lines = [line.strip() for line in clean_text.splitlines()]
    # Filter out empty lines but keep a single newline for separation if multiple were there
    filtered_lines = []
    last_line_was_content = False
    for line in lines:
        if line:
            filtered_lines.append(line)
            last_line_was_content = True
        elif last_line_was_content: # Keep one empty line if it was separating content
            filtered_lines.append("") 
            last_line_was_content = False
    
    # Join and then strip leading/trailing newlines from the whole block
    clean_text = '\n'.join(filtered_lines).strip()
    # Ensure at least one newline between paragraphs if they were merged by tag removal
    clean_text = re.sub(r'(?<=[×-í£a-zA-Z0-9])\n(?=[×-í£a-zA-Z0-9])', '\n\n', clean_text) 
    return clean_text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ê¸°ë³¸ ìƒìˆ˜ (ì´ì „ê³¼ ë™ì¼)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FILE_NAME = "Jeolgi_1900_2100_20250513.xlsx"

GAN = ["ê°‘", "ì„", "ë³‘", "ì •", "ë¬´", "ê¸°", "ê²½", "ì‹ ", "ì„", "ê³„"]
JI  = ["ì", "ì¶•", "ì¸", "ë¬˜", "ì§„", "ì‚¬", "ì˜¤", "ë¯¸", "ì‹ ", "ìœ ", "ìˆ ", "í•´"]

SAJU_MONTH_TERMS_ORDER = [
    "ì…ì¶˜", "ê²½ì¹©", "ì²­ëª…", "ì…í•˜", "ë§ì¢…", "ì†Œì„œ",
    "ì…ì¶”", "ë°±ë¡œ", "í•œë¡œ", "ì…ë™", "ëŒ€ì„¤", "ì†Œí•œ"
]
SAJU_MONTH_BRANCHES = ["ì¸","ë¬˜","ì§„","ì‚¬","ì˜¤","ë¯¸","ì‹ ","ìœ ","ìˆ ","í•´","ì","ì¶•"]

TIME_BRANCH_MAP = [
    ((23,30),(1,29),"ì",0),((1,30),(3,29),"ì¶•",1),((3,30),(5,29),"ì¸",2),
    ((5,30),(7,29),"ë¬˜",3),((7,30),(9,29),"ì§„",4),((9,30),(11,29),"ì‚¬",5),
    ((11,30),(13,29),"ì˜¤",6),((13,30),(15,29),"ë¯¸",7),((15,30),(17,29),"ì‹ ",8),
    ((17,30),(19,29),"ìœ ",9),((19,30),(21,29),"ìˆ ",10),((21,30),(23,29),"í•´",11)
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¶”ê°€ ìƒìˆ˜ ì •ì˜ (ì˜¤í–‰, ì§€ì¥ê°„, ì‹­ì‹  ë“±)
# (ì‚¬ìš©ìë‹˜ì´ ì œê³µí•´ì£¼ì‹  HTML/JS ì˜ˆì œ ì½”ë“œì˜ ìƒìˆ˜ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GAN_TO_OHENG = {
    "ê°‘": "ëª©", "ì„": "ëª©", "ë³‘": "í™”", "ì •": "í™”", "ë¬´": "í† ",
    "ê¸°": "í† ", "ê²½": "ê¸ˆ", "ì‹ ": "ê¸ˆ", "ì„": "ìˆ˜", "ê³„": "ìˆ˜"
}

JIJI_JANGGAN = {
    "ì": {"ê³„": 1.0},
    "ì¶•": {"ê¸°": 0.5, "ê³„": 0.3, "ì‹ ": 0.2},
    "ì¸": {"ê°‘": 0.5, "ë³‘": 0.3, "ë¬´": 0.2},
    "ë¬˜": {"ì„": 1.0},
    "ì§„": {"ë¬´": 0.5, "ì„": 0.3, "ê³„": 0.2},
    "ì‚¬": {"ë³‘": 0.5, "ë¬´": 0.3, "ê²½": 0.2},
    "ì˜¤": {"ì •": 0.7, "ê¸°": 0.3},
    "ë¯¸": {"ê¸°": 0.5, "ì •": 0.3, "ì„": 0.2},
    "ì‹ ": {"ê²½": 0.5, "ì„": 0.3, "ë¬´": 0.2},
    "ìœ ": {"ì‹ ": 1.0},
    "ìˆ ": {"ë¬´": 0.5, "ì‹ ": 0.3, "ì •": 0.2},
    "í•´": {"ì„": 0.7, "ê°‘": 0.3}
}

POSITIONAL_WEIGHTS = {
    "ì—°ê°„": 0.7, "ì—°ì§€": 0.9, "ì›”ê°„": 0.9, "ì›”ì§€": 2.1,
    "ì¼ê°„": 0.5, "ì¼ì§€": 1.9, "ì‹œê°„": 0.8, "ì‹œì§€": 1.0
}
POSITION_KEYS_ORDERED = ["ì—°ê°„", "ì—°ì§€", "ì›”ê°„", "ì›”ì§€", "ì¼ê°„", "ì¼ì§€", "ì‹œê°„", "ì‹œì§€"]


SIPSHIN_MAP = {
    "ê°‘": {"ê°‘": "ë¹„ê²¬", "ì„": "ê²ì¬", "ë³‘": "ì‹ì‹ ", "ì •": "ìƒê´€", "ë¬´": "í¸ì¬", "ê¸°": "ì •ì¬", "ê²½": "í¸ê´€", "ì‹ ": "ì •ê´€", "ì„": "í¸ì¸", "ê³„": "ì •ì¸"},
    "ì„": {"ê°‘": "ê²ì¬", "ì„": "ë¹„ê²¬", "ë³‘": "ìƒê´€", "ì •": "ì‹ì‹ ", "ë¬´": "ì •ì¬", "ê¸°": "í¸ì¬", "ê²½": "ì •ê´€", "ì‹ ": "í¸ê´€", "ì„": "ì •ì¸", "ê³„": "í¸ì¸"},
    "ë³‘": {"ê°‘": "í¸ì¸", "ì„": "ì •ì¸", "ë³‘": "ë¹„ê²¬", "ì •": "ê²ì¬", "ë¬´": "ì‹ì‹ ", "ê¸°": "ìƒê´€", "ê²½": "í¸ì¬", "ì‹ ": "ì •ì¬", "ì„": "í¸ê´€", "ê³„": "ì •ê´€"},
    "ì •": {"ê°‘": "ì •ì¸", "ì„": "í¸ì¸", "ë³‘": "ê²ì¬", "ì •": "ë¹„ê²¬", "ë¬´": "ìƒê´€", "ê¸°": "ì‹ì‹ ", "ê²½": "ì •ì¬", "ì‹ ": "í¸ì¬", "ì„": "ì •ê´€", "ê³„": "í¸ê´€"},
    "ë¬´": {"ê°‘": "í¸ê´€", "ì„": "ì •ê´€", "ë³‘": "í¸ì¸", "ì •": "ì •ì¸", "ë¬´": "ë¹„ê²¬", "ê¸°": "ê²ì¬", "ê²½": "ì‹ì‹ ", "ì‹ ": "ìƒê´€", "ì„": "í¸ì¬", "ê³„": "ì •ì¬"},
    "ê¸°": {"ê°‘": "ì •ê´€", "ì„": "í¸ê´€", "ë³‘": "ì •ì¸", "ì •": "í¸ì¸", "ë¬´": "ê²ì¬", "ê¸°": "ë¹„ê²¬", "ê²½": "ìƒê´€", "ì‹ ": "ì‹ì‹ ", "ì„": "ì •ì¬", "ê³„": "í¸ì¬"},
    "ê²½": {"ê°‘": "í¸ì¬", "ì„": "ì •ì¬", "ë³‘": "í¸ê´€", "ì •": "ì •ê´€", "ë¬´": "í¸ì¸", "ê¸°": "ì •ì¸", "ê²½": "ë¹„ê²¬", "ì‹ ": "ê²ì¬", "ì„": "ì‹ì‹ ", "ê³„": "ìƒê´€"},
    "ì‹ ": {"ê°‘": "ì •ì¬", "ì„": "í¸ì¬", "ë³‘": "ì •ê´€", "ì •": "í¸ê´€", "ë¬´": "ì •ì¸", "ê¸°": "í¸ì¸", "ê²½": "ê²ì¬", "ì‹ ": "ë¹„ê²¬", "ì„": "ìƒê´€", "ê³„": "ì‹ì‹ "},
    "ì„": {"ê°‘": "ì‹ì‹ ", "ì„": "ìƒê´€", "ë³‘": "í¸ì¬", "ì •": "ì •ì¬", "ë¬´": "í¸ê´€", "ê¸°": "ì •ê´€", "ê²½": "í¸ì¸", "ì‹ ": "ì •ì¸", "ì„": "ë¹„ê²¬", "ê³„": "ê²ì¬"},
    "ê³„": {"ê°‘": "ìƒê´€", "ì„": "ì‹ì‹ ", "ë³‘": "ì •ì¬", "ì •": "í¸ì¬", "ë¬´": "ì •ê´€", "ê¸°": "í¸ê´€", "ê²½": "ì •ì¸", "ì‹ ": "í¸ì¸", "ì„": "ê²ì¬", "ê³„": "ë¹„ê²¬"}
}

OHENG_ORDER = ["ëª©", "í™”", "í† ", "ê¸ˆ", "ìˆ˜"]
SIPSHIN_ORDER = ["ë¹„ê²¬", "ê²ì¬", "ì‹ì‹ ", "ìƒê´€", "í¸ì¬", "ì •ì¬", "í¸ê´€", "ì •ê´€", "í¸ì¸", "ì •ì¸"]

OHENG_TO_HANJA = {"ëª©": "æœ¨", "í™”": "ç«", "í† ": "åœŸ", "ê¸ˆ": "é‡‘", "ìˆ˜": "æ°´"}
OHAENG_DESCRIPTIONS = {
    "ëª©": "ì„±ì¥, ì‹œì‘, ì¸ìí•¨", "í™”": "ì—´ì •, í‘œí˜„, ì˜ˆì˜", "í† ": "ì•ˆì •, ì¤‘ì¬, ì‹ ìš©",
    "ê¸ˆ": "ê²°ì‹¤, ì˜ë¦¬, ê²°ë‹¨", "ìˆ˜": "ì§€í˜œ, ìœ ì—°, ì €ì¥"
}
SIPSHIN_COLORS = {
    "ë¹„ê²¬": "#1d4ed8", "ê²ì¬": "#1d4ed8", # ë¹„ê²
    "ì‹ì‹ ": "#c2410c", "ìƒê´€": "#c2410c", # ì‹ìƒ
    "í¸ì¬": "#ca8a04", "ì •ì¬": "#ca8a04", # ì¬ì„±
    "í¸ê´€": "#166534", "ì •ê´€": "#166534", # ê´€ì„±
    "í¸ì¸": "#6b7280", "ì •ì¸": "#6b7280"  # ì¸ì„±
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹ ê°•/ì‹ ì•½ ë° ê²©êµ­ ë¶„ì„ìš© ìƒìˆ˜ ì¶”ê°€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
L_NOK_MAP = {
    "ê°‘": "ë¬˜", "ì„": "ì¸", "ë³‘": "ì‚¬", "ì •": "ì˜¤",
    "ë¬´": "ì§„", "ê¸°": "ì¶•", "ê²½": "ìœ ", "ì‹ ": "ì‹ ",
    "ì„": "í•´", "ê³„": "ì"
}
YANGIN_JI_MAP = {
    "ê°‘": "ë¬˜", "ë³‘": "ì˜¤", "ë¬´": "ì˜¤", "ê²½": "ìœ ", "ì„": "ì"
}
SIPSHIN_TO_GYEOK_MAP = {
    'ë¹„ê²¬':'ë¹„ê²¬ê²©', 'ê²ì¬':'ê²ì¬ê²©',
    'ì‹ì‹ ':'ì‹ì‹ ê²©', 'ìƒê´€':'ìƒê´€ê²©',
    'í¸ì¬':'í¸ì¬ê²©', 'ì •ì¬':'ì •ì¬ê²©',
    'í¸ê´€':'ì¹ ì‚´ê²©', 'ì •ê´€':'ì •ê´€ê²©',
    'í¸ì¸':'í¸ì¸ê²©', 'ì •ì¸':'ì •ì¸ê²©'
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹ ê°•/ì‹ ì•½ íŒë‹¨ ë° ì„¤ëª… í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def determine_shinkang_shinyak(sipshin_strengths):
    my_energy = (sipshin_strengths.get("ë¹„ê²¬", 0.0) +
                 sipshin_strengths.get("ê²ì¬", 0.0) +
                 sipshin_strengths.get("í¸ì¸", 0.0) +
                 sipshin_strengths.get("ì •ì¸", 0.0))
    opponent_energy = (sipshin_strengths.get("ì‹ì‹ ", 0.0) +
                       sipshin_strengths.get("ìƒê´€", 0.0) +
                       sipshin_strengths.get("í¸ì¬", 0.0) +
                       sipshin_strengths.get("ì •ì¬", 0.0) +
                       sipshin_strengths.get("í¸ê´€", 0.0) +
                       sipshin_strengths.get("ì •ê´€", 0.0))
    score_diff = my_energy - opponent_energy
    if score_diff >= 1.5: return "ì‹ ê°•"
    elif score_diff <= -1.5: return "ì‹ ì•½"
    elif -0.5 <= score_diff <= 0.5: return "ì¤‘í™”"
    elif score_diff > 0.5: return "ì•½ê°„ ì‹ ê°•"
    else: return "ì•½ê°„ ì‹ ì•½"

def get_shinkang_explanation(shinkang_status_str):
    explanations = {
        "ì‹ ê°•": "ì¼ê°„(ìì‹ )ì˜ í˜ì´ ê°•í•œ í¸ì…ë‹ˆë‹¤. ì£¼ì²´ì ì´ê³  ë…ë¦½ì ì¸ ì„±í–¥ì´ ê°•í•˜ë©°, ìì‹ ì˜ ì˜ì§€ëŒ€ë¡œ ì¼ì„ ì¶”ì§„í•˜ëŠ” í˜ì´ ìˆìŠµë‹ˆë‹¤. ë•Œë¡œëŠ” ìê¸° ì£¼ì¥ì´ ê°•í•´ ì£¼ë³€ê³¼ì˜ ë§ˆì°°ì´ ìƒê¸¸ ìˆ˜ ìˆìœ¼ë‹ˆ ìœ ì—°ì„±ì„ ê°–ì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.",
        "ì‹ ì•½": "ì¼ê°„(ìì‹ )ì˜ í˜ì´ ë‹¤ì†Œ ì•½í•œ í¸ì…ë‹ˆë‹¤. ì£¼ë³€ì˜ ë„ì›€ì´ë‚˜ í™˜ê²½ì˜ ì˜í–¥ì— ë¯¼ê°í•˜ë©°, ì‹ ì¤‘í•˜ê³  ì‚¬ë ¤ ê¹Šì€ ëª¨ìŠµì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìì‹ ê°ì„ ê°–ê³  ê¾¸ì¤€íˆ ìì‹ ì˜ ì—­ëŸ‰ì„ í‚¤ì›Œë‚˜ê°€ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ì¢‹ì€ ìš´ì˜ íë¦„ì„ ì˜ í™œìš©í•˜ëŠ” ì§€í˜œê°€ í•„ìš”í•©ë‹ˆë‹¤.",
        "ì¤‘í™”": "ì¼ê°„(ìì‹ )ì˜ í˜ì´ ë¹„êµì  ê· í˜•ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ìƒí™©ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•˜ëŠ” ëŠ¥ë ¥ì´ ìˆìœ¼ë©°, ì›ë§Œí•œ ëŒ€ì¸ê´€ê³„ë¥¼ ë§ºì„ ìˆ˜ ìˆëŠ” ì¢‹ì€ êµ¬ì¡°ì…ë‹ˆë‹¤. ë‹¤ë§Œ, ë•Œë¡œëŠ” ëšœë ·í•œ ê°œì„±ì´ ë¶€ì¡±í•´ ë³´ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.",
        "ì•½ê°„ ì‹ ê°•": "ì¼ê°„(ìì‹ )ì˜ í˜ì´ í‰ê· ë³´ë‹¤ ì¡°ê¸ˆ ê°•í•œ í¸ì…ë‹ˆë‹¤. ìì‹ ì˜ ì£¼ê´€ì„ ê°€ì§€ê³  ì¼ì„ ì²˜ë¦¬í•˜ë©´ì„œë„ ì£¼ë³€ê³¼ í˜‘ë ¥í•˜ëŠ” ê· í˜• ê°ê°ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ì•½ê°„ ì‹ ì•½": "ì¼ê°„(ìì‹ )ì˜ í˜ì´ í‰ê· ë³´ë‹¤ ì¡°ê¸ˆ ì•½í•œ í¸ì…ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê³  ì£¼ë³€ ìƒí™©ì„ ì˜ ì‚´í”¼ë©°, ì¸ë‚´ì‹¬ì„ ê°€ì§€ê³  ëª©í‘œë¥¼ ì¶”êµ¬í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì£¼ë³€ì˜ ì¡°ì–¸ì„ ê²½ì²­í•˜ëŠ” ìì„¸ê°€ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }
    return explanations.get(shinkang_status_str, "ì¼ê°„ì˜ ê°•ì•½ ìƒíƒœì— ëŒ€í•œ ì„¤ëª…ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²©êµ­ íŒë‹¨ í•¨ìˆ˜ë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _detect_special_gekuk(day_gan_char, month_ji_char):
    if L_NOK_MAP.get(day_gan_char) == month_ji_char: return "ê±´ë¡ê²©"
    if day_gan_char in YANGIN_JI_MAP and YANGIN_JI_MAP.get(day_gan_char) == month_ji_char: return "ì–‘ì¸ê²©"
    return None

def _detect_togan_gekuk(day_gan_char, month_gan_char, month_ji_char):
    if month_ji_char in JIJI_JANGGAN:
        hidden_stems_in_month_ji = JIJI_JANGGAN[month_ji_char]
        if month_gan_char in hidden_stems_in_month_ji:
            sipshin_type = SIPSHIN_MAP.get(day_gan_char, {}).get(month_gan_char)
            if sipshin_type: return SIPSHIN_TO_GYEOK_MAP.get(sipshin_type, sipshin_type + "ê²©")
    return None

def _detect_general_gekuk_from_month_branch_primary(day_gan_char, month_ji_char):
    if month_ji_char in JIJI_JANGGAN:
        hidden_stems = JIJI_JANGGAN[month_ji_char]
        if hidden_stems:
            primary_hidden_stem = max(hidden_stems, key=hidden_stems.get) if hidden_stems else None
            if primary_hidden_stem:
                sipshin_type = SIPSHIN_MAP.get(day_gan_char, {}).get(primary_hidden_stem)
                if sipshin_type: return SIPSHIN_TO_GYEOK_MAP.get(sipshin_type, sipshin_type + "ê²©")
    return None

def _detect_general_gekuk_from_strengths(sipshin_strengths_dict):
    if not sipshin_strengths_dict: return None
    strongest_sipshin_name = None
    max_strength = -1
    for sipshin_name in SIPSHIN_ORDER:
        strength_val = sipshin_strengths_dict.get(sipshin_name, 0.0)
        if strength_val > max_strength:
            max_strength = strength_val
            strongest_sipshin_name = sipshin_name
    if strongest_sipshin_name and max_strength > 0.5:
        return SIPSHIN_TO_GYEOK_MAP.get(strongest_sipshin_name, strongest_sipshin_name + "ê²©")
    return "ì¼ë°˜ê²© íŒì • ì–´ë ¤ì›€"

def determine_gekuk(day_gan_char, month_gan_char, month_ji_char, sipshin_strengths_dict):
    special_gekuk = _detect_special_gekuk(day_gan_char, month_ji_char)
    if special_gekuk: return special_gekuk
    togan_gekuk = _detect_togan_gekuk(day_gan_char, month_gan_char, month_ji_char)
    if togan_gekuk: return togan_gekuk
    month_branch_primary_gekuk = _detect_general_gekuk_from_month_branch_primary(day_gan_char, month_ji_char)
    if month_branch_primary_gekuk: return month_branch_primary_gekuk
    strength_based_gekuk = _detect_general_gekuk_from_strengths(sipshin_strengths_dict)
    if strength_based_gekuk and strength_based_gekuk != "ì¼ë°˜ê²© íŒì • ì–´ë ¤ì›€": return strength_based_gekuk
    elif strength_based_gekuk == "ì¼ë°˜ê²© íŒì • ì–´ë ¤ì›€": return strength_based_gekuk
    return "ê²©êµ­ íŒì • ë¶ˆê°€"

def get_gekuk_explanation(gekuk_name_str):
    explanations = {
        'ê±´ë¡ê²©': 'ìŠ¤ìŠ¤ë¡œ ìë¦½í•˜ì—¬ ì„±ê³µí•˜ëŠ” ììˆ˜ì„±ê°€í˜• ë¦¬ë” íƒ€ì…ì…ë‹ˆë‹¤! êµ³ê±´í•˜ê³  ë…ë¦½ì ì¸ ì„±í–¥ì„ ê°€ì¡ŒìŠµë‹ˆë‹¤. (ì£¼ë¡œ ì›”ì§€ì— ì¼ê°„ì˜ ê±´ë¡ì´ ìˆëŠ” ê²½ìš°)',
        'ì–‘ì¸ê²©': 'ê°•ë ¥í•œ ì¹´ë¦¬ìŠ¤ë§ˆì™€ ëŒíŒŒë ¥ì„ ì§€ë…”ìŠµë‹ˆë‹¤! ë•Œë¡œëŠ” ë„ˆë¬´ ê°•í•œ ê¸°ìš´ìœ¼ë¡œ ì¸í•´ ì¡°ì ˆì´ í•„ìš”í•  ìˆ˜ ìˆì§€ë§Œ, í°ì¼ì„ í•´ë‚¼ ìˆ˜ ìˆëŠ” ì €ë ¥ì´ ìˆìŠµë‹ˆë‹¤. (ì£¼ë¡œ ì›”ì§€ì— ì–‘ì¼ê°„ì˜ ì–‘ì¸ì´ ìˆëŠ” ê²½ìš°)',
        'ë¹„ê²¬ê²©': 'ì£¼ì²´ì„±ì´ ê°•í•˜ê³  ë™ë£Œë“¤ê³¼ í˜‘ë ¥í•˜ë©° ëª©í‘œë¥¼ í–¥í•´ ë‚˜ì•„ê°€ëŠ” íƒ€ì…ì…ë‹ˆë‹¤. ë…ë¦½ì‹¬ê³¼ ìì¡´ê°ì´ ê°•í•œ í¸ì…ë‹ˆë‹¤.',
        'ê²ì¬ê²©': 'ìŠ¹ë¶€ìš•ê³¼ ê²½ìŸì‹¬ì´ ê°•í•˜ë©°, ë•Œë¡œëŠ” ê³¼ê°í•œ ë„ì „ë„ ë¶ˆì‚¬í•˜ëŠ” ì ê·¹ì ì¸ ë©´ëª¨ê°€ ìˆìŠµë‹ˆë‹¤. ì£¼ë³€ê³¼ì˜ í˜‘ë ¥ê³¼ ì¡°í™”ë¥¼ ì¤‘ìš”ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.',
        'ì‹ì‹ ê²©': 'ë‚™ì²œì ì´ê³  ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ê°€ í’ë¶€í•˜ë©°, í‘œí˜„ë ¥ì´ ì¢‹ê³  ì˜ˆìˆ ì  ì¬ëŠ¥ì„ ì§€ë…”ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ˆì •ì ì¸ ì˜ì‹ì£¼ë¥¼ ì¤‘ì‹œí•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.',
        'ìƒê´€ê²©': 'ìƒˆë¡œìš´ ê²ƒì„ íƒêµ¬í•˜ê³  ê¸°ì¡´ì˜ í‹€ì„ ê¹¨ë ¤ëŠ” í˜ì‹ ê°€ì  ê¸°ì§ˆì´ ìˆìŠµë‹ˆë‹¤. ë¹„íŒì ì´ê³  ë‚ ì¹´ë¡œìš´ í†µì°°ë ¥ì„ ì§€ë…”ì§€ë§Œ, ë•Œë¡œëŠ” í‘œí˜„ ë°©ì‹ì— ìœ ì˜í•˜ì—¬ ì˜¤í•´ë¥¼ í”¼í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.',
        'í¸ì¬ê²©': 'í™œë™ì ì´ê³  ì‚¬êµì„±ì´ ë›°ì–´ë‚˜ë©° ì‚¬ëŒë“¤ê³¼ ì–´ìš¸ë¦¬ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤. ì¬ë¬¼ì— ëŒ€í•œ ê°ê°ê³¼ ìš´ìš© ëŠ¥ë ¥ì´ ë›°ì–´ë‚˜ë©°, ìŠ¤ì¼€ì¼ì´ í¬ê³  í†µì´ í° ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.',
        'ì •ì¬ê²©': 'ê¼¼ê¼¼í•˜ê³  ì„±ì‹¤í•˜ë©° ì•ˆì •ì ì¸ ê²ƒì„ ì„ í˜¸í•©ë‹ˆë‹¤. ì‹ ìš©ì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ê³  ê³„íšì ì¸ ì‚¶ì„ ì¶”êµ¬í•˜ë©°, ì¬ë¬¼ì„ ì•ˆì •ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì´ ìˆìŠµë‹ˆë‹¤.',
        'ì¹ ì‚´ê²©': 'ëª…ì˜ˆë¥¼ ì¤‘ì‹œí•˜ê³  ë¦¬ë”ì‹­ì´ ìˆìœ¼ë©°, ì–´ë ¤ìš´ ìƒí™©ì„ ê·¹ë³µí•˜ê³  ìœ„ê¸°ì—ì„œ ëŠ¥ë ¥ì„ ë°œíœ˜í•˜ëŠ” ì¹´ë¦¬ìŠ¤ë§ˆê°€ ìˆìŠµë‹ˆë‹¤. (í¸ê´€ê²©ê³¼ ìœ ì‚¬)',
        'ì •ê´€ê²©': 'ì›ì¹™ì„ ì§€í‚¤ëŠ” ë°˜ë“¯í•˜ê³  í•©ë¦¬ì ì¸ ì„±í–¥ì…ë‹ˆë‹¤. ëª…ì˜ˆì™€ ì•ˆì •ì„ ì¶”êµ¬í•˜ë©° ì¡°ì§ ìƒí™œì— ì˜ ì ì‘í•˜ê³  ì±…ì„ê°ì´ ê°•í•©ë‹ˆë‹¤.',
        'í¸ì¸ê²©': 'ì§ê´€ë ¥ê³¼ ì˜ˆì§€ë ¥ì´ ë›°ì–´ë‚˜ë©°, ë…íŠ¹í•œ ì•„ì´ë””ì–´ë‚˜ ì˜ˆìˆ , ì² í•™, ì¢…êµ ë“± ì •ì‹ ì ì¸ ë¶„ì•¼ì— ì¬ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì†Œ ìƒê°ì´ ë§ê±°ë‚˜ ë³€ë•ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'ì •ì¸ê²©': 'í•™ë¬¸ê³¼ ì§€ì‹ì„ ì‚¬ë‘í•˜ê³  ì¸ì •ì´ ë§ìœ¼ë©° ìˆ˜ìš©ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤. ì•ˆì •ì ì¸ í™˜ê²½ì—ì„œ ëŠ¥ë ¥ì„ ë°œíœ˜í•˜ë©°, íƒ€ì¸ì—ê²Œ ë„ì›€ì„ ì£¼ëŠ” ê²ƒì„ ì¢‹ì•„í•©ë‹ˆë‹¤.',
        'ì¼ë°˜ê²© íŒì • ì–´ë ¤ì›€': 'ì‚¬ì£¼ì˜ ê¸°ìš´ì´ ë³µí•©ì ì´ê±°ë‚˜ íŠ¹ì • ì‹­ì‹ ì˜ ì„¸ë ¥ì´ ë‘ë“œëŸ¬ì§€ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•Šì•„, í•˜ë‚˜ì˜ ì£¼ëœ ê²©êµ­ìœ¼ë¡œ ì •ì˜í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ê°€ëŠ¥ì„±ì„ ê°€ì§„ ì‚¬ì£¼ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©°, ìš´ì˜ íë¦„ì— ë”°ë¼ ì—¬ëŸ¬ ê²©ì˜ íŠ¹ì„±ì´ ë°œí˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'ê²©êµ­ íŒì • ë¶ˆê°€': 'ì‚¬ì£¼ì˜ êµ¬ì¡°ìƒ íŠ¹ì • ê²©êµ­ì„ ëª…í™•íˆ íŒì •í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ì‚¬ì£¼ ì „ì²´ì˜ ì˜¤í–‰ ë° ì‹­ì‹  ë¶„í¬, ìš´ì˜ íë¦„ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ íŒë‹¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.'
    }
    if gekuk_name_str == 'í¸ê´€ê²©': gekuk_name_str = 'ì¹ ì‚´ê²©'
    return explanations.get(gekuk_name_str, f"'{gekuk_name_str}'ì— ëŒ€í•œ ì„¤ëª…ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ í•´ë‹¹ ì‹­ì‹ ì˜ íŠ¹ì„±ì„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

import itertools

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•©ì¶©í˜•í•´íŒŒ ë¶„ì„ìš© ìƒìˆ˜ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHEONGAN_HAP_RULES = {
    tuple(sorted(("ê°‘", "ê¸°"))): "í† ", tuple(sorted(("ì„", "ê²½"))): "ê¸ˆ",
    tuple(sorted(("ë³‘", "ì‹ "))): "ìˆ˜", tuple(sorted(("ì •", "ì„"))): "ëª©",
    tuple(sorted(("ë¬´", "ê³„"))): "í™”"
}
JIJI_SAMHAP_RULES = {
    tuple(sorted(("ì‹ ", "ì", "ì§„"))): "ìˆ˜êµ­(æ°´å±€)", tuple(sorted(("ì‚¬", "ìœ ", "ì¶•"))): "ê¸ˆêµ­(é‡‘å±€)",
    tuple(sorted(("ì¸", "ì˜¤", "ìˆ "))): "í™”êµ­(ç«å±€)", tuple(sorted(("í•´", "ë¬˜", "ë¯¸"))): "ëª©êµ­(æœ¨å±€)"
}
JIJI_BANHAP_WANGJI_CENTERED_RULES = {
    "ì": ["ì‹ ", "ì§„"], "ìœ ": ["ì‚¬", "ì¶•"], "ì˜¤": ["ì¸", "ìˆ "], "ë¬˜": ["í•´", "ë¯¸"]
}
JIJI_BANGHAP_RULES = {
    tuple(sorted(("ì¸", "ë¬˜", "ì§„"))): "ëª©êµ­(æœ¨å±€)", tuple(sorted(("ì‚¬", "ì˜¤", "ë¯¸"))): "í™”êµ­(ç«å±€)",
    tuple(sorted(("ì‹ ", "ìœ ", "ìˆ "))): "ê¸ˆêµ­(é‡‘å±€)", tuple(sorted(("í•´", "ì", "ì¶•"))): "ìˆ˜êµ­(æ°´å±€)"
}
JIJI_YUKHAP_RULES = {
    tuple(sorted(("ì", "ì¶•"))): "í† ", tuple(sorted(("ì¸", "í•´"))): "ëª©",
    tuple(sorted(("ë¬˜", "ìˆ "))): "í™”", tuple(sorted(("ì§„", "ìœ "))): "ê¸ˆ",
    tuple(sorted(("ì‚¬", "ì‹ "))): "ìˆ˜", tuple(sorted(("ì˜¤", "ë¯¸"))): "í™”/í† "
}
CHEONGAN_CHUNG_RULES = [
    tuple(sorted(("ê°‘", "ê²½"))), tuple(sorted(("ì„", "ì‹ "))),
    tuple(sorted(("ë³‘", "ì„"))), tuple(sorted(("ì •", "ê³„")))
]
JIJI_CHUNG_RULES = [
    tuple(sorted(("ì", "ì˜¤"))), tuple(sorted(("ì¶•", "ë¯¸"))), tuple(sorted(("ì¸", "ì‹ "))),
    tuple(sorted(("ë¬˜", "ìœ "))), tuple(sorted(("ì§„", "ìˆ "))), tuple(sorted(("ì‚¬", "í•´")))
]
SAMHYEONG_RULES = {
    tuple(sorted(("ì¸", "ì‚¬", "ì‹ "))): "ì¸ì‚¬ì‹  ì‚¼í˜•(ç„¡æ©ä¹‹åˆ‘)",
    tuple(sorted(("ì¶•", "ìˆ ", "ë¯¸"))): "ì¶•ìˆ ë¯¸ ì‚¼í˜•(æŒå‹¢ä¹‹åˆ‘)"
}
SANGHYEONG_RULES = [tuple(sorted(("ì", "ë¬˜")))]
JAHYEONG_CHARS = ["ì§„", "ì˜¤", "ìœ ", "í•´"]
JIJI_HAE_RULES = [
    tuple(sorted(("ì", "ë¯¸"))), tuple(sorted(("ì¶•", "ì˜¤"))), tuple(sorted(("ì¸", "ì‚¬"))),
    tuple(sorted(("ë¬˜", "ì§„"))), tuple(sorted(("ì‹ ", "í•´"))), tuple(sorted(("ìœ ", "ìˆ ")))
]
HAE_NAMES = {tuple(sorted(k)):v for k,v in {"ìë¯¸":"ìë¯¸í•´", "ì¶•ì˜¤":"ì¶•ì˜¤í•´", "ì¸ì‚¬":"ì¸ì‚¬íšŒ", "ë¬˜ì§„":"ë¬˜ì§„í•´", "ì‹ í•´":"ì‹ í•´í•´", "ìœ ìˆ ":"ìœ ìˆ í•´"}.items()}
JIJI_PA_RULES = [
    tuple(sorted(("ì", "ìœ "))), tuple(sorted(("ì¶•", "ì§„"))), tuple(sorted(("ì¸", "í•´"))),
    tuple(sorted(("ë¬˜", "ì˜¤"))), tuple(sorted(("ì‚¬", "ì‹ "))), tuple(sorted(("ìˆ ", "ë¯¸")))
]
PA_NAMES = {tuple(sorted(k)):v for k,v in {"ììœ ":"ììœ íŒŒ", "ì¶•ì§„":"ì¶•ì§„íŒŒ", "ì¸í•´":"ì¸í•´íŒŒ", "ë¬˜ì˜¤":"ë¬˜ì˜¤íŒŒ", "ì‚¬ì‹ ":"ì‚¬ì‹ íŒŒ", "ìˆ ë¯¸":"ìˆ ë¯¸íŒŒ"}.items()}
PILLAR_NAMES_KOR_SHORT = ["ë…„", "ì›”", "ì¼", "ì‹œ"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•©ì¶©í˜•í•´íŒŒ ë¶„ì„ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def analyze_hap_chung_interactions(saju_8char_details):
    gans = [saju_8char_details["year_gan"], saju_8char_details["month_gan"], saju_8char_details["day_gan"], saju_8char_details["time_gan"]]
    jis = [saju_8char_details["year_ji"], saju_8char_details["month_ji"], saju_8char_details["day_ji"], saju_8char_details["time_ji"]]
    results = {
        "ì²œê°„í•©": [], "ì§€ì§€ìœ¡í•©": [], "ì§€ì§€ì‚¼í•©": [], "ì§€ì§€ë°©í•©": [],
        "ì²œê°„ì¶©": [], "ì§€ì§€ì¶©": [], "í˜•ì‚´(åˆ‘æ®º)": [], "í•´ì‚´(å®³æ®º)": [], "íŒŒì‚´(ç ´æ®º)": []
    }
    found_samhap_banhap_combinations = set()
    gans_with_pos = list(enumerate(gans))
    jis_with_pos = list(enumerate(jis))

    for (i_idx, i_gan), (j_idx, j_gan) in itertools.combinations(gans_with_pos, 2):
        pair_sorted = tuple(sorted((i_gan, j_gan)))
        pos_str = f"{PILLAR_NAMES_KOR_SHORT[i_idx]}ê°„({i_gan}) + {PILLAR_NAMES_KOR_SHORT[j_idx]}ê°„({j_gan})"
        if pair_sorted in CHEONGAN_HAP_RULES: results["ì²œê°„í•©"].append(f"{pos_str} â†’ {CHEONGAN_HAP_RULES[pair_sorted]} í•©")
        if pair_sorted in CHEONGAN_CHUNG_RULES: results["ì²œê°„ì¶©"].append(f"{pos_str.replace('+', 'â†”')} ì¶©")

    for (i_idx, i_ji), (j_idx, j_ji) in itertools.combinations(jis_with_pos, 2):
        pair_sorted = tuple(sorted((i_ji, j_ji)))
        pos_str = f"{PILLAR_NAMES_KOR_SHORT[i_idx]}ì§€({i_ji}) + {PILLAR_NAMES_KOR_SHORT[j_idx]}ì§€({j_ji})"
        if pair_sorted in JIJI_YUKHAP_RULES: results["ì§€ì§€ìœ¡í•©"].append(f"{pos_str} â†’ {JIJI_YUKHAP_RULES[pair_sorted]} í•©")
        if pair_sorted in JIJI_CHUNG_RULES: results["ì§€ì§€ì¶©"].append(f"{pos_str.replace('+', 'â†”')} ì¶©")
        if pair_sorted in JIJI_HAE_RULES: results["í•´ì‚´(å®³æ®º)"].append(f"{pos_str} â†’ {HAE_NAMES.get(pair_sorted, 'í•´')}")
        if pair_sorted in JIJI_PA_RULES: results["íŒŒì‚´(ç ´æ®º)"].append(f"{pos_str} â†’ {PA_NAMES.get(pair_sorted, 'íŒŒ')}")
        if pair_sorted in SANGHYEONG_RULES: results["í˜•ì‚´(åˆ‘æ®º)"].append(f"{pos_str} â†’ ìë¬˜ ìƒí˜•(ç„¡ç¦®ä¹‹åˆ‘)")

    for (i_idx, i_ji), (j_idx, j_ji), (k_idx, k_ji) in itertools.combinations(jis_with_pos, 3):
        combo_sorted = tuple(sorted((i_ji, j_ji, k_ji)))
        pos_str = f"{PILLAR_NAMES_KOR_SHORT[i_idx]}ì§€({i_ji}), {PILLAR_NAMES_KOR_SHORT[j_idx]}ì§€({j_ji}), {PILLAR_NAMES_KOR_SHORT[k_idx]}ì§€({k_ji})"
        if combo_sorted in JIJI_SAMHAP_RULES:
            found_samhap_banhap_combinations.add(combo_sorted)
            results["ì§€ì§€ì‚¼í•©"].append(f"{pos_str} â†’ {JIJI_SAMHAP_RULES[combo_sorted]}")
        if combo_sorted in JIJI_BANGHAP_RULES: results["ì§€ì§€ë°©í•©"].append(f"{pos_str} â†’ {JIJI_BANGHAP_RULES[combo_sorted]}")
        if combo_sorted in SAMHYEONG_RULES: results["í˜•ì‚´(åˆ‘æ®º)"].append(f"{pos_str} â†’ {SAMHYEONG_RULES[combo_sorted]}")

    for (i_idx, i_ji), (j_idx, j_ji) in itertools.combinations(jis_with_pos, 2):
        pos_str = f"{PILLAR_NAMES_KOR_SHORT[i_idx]}ì§€({i_ji}) + {PILLAR_NAMES_KOR_SHORT[j_idx]}ì§€({j_ji})"
        for wangji, others in JIJI_BANHAP_WANGJI_CENTERED_RULES.items():
            if (i_ji == wangji and j_ji in others) or (j_ji == wangji and i_ji in others):
                is_part_of_samhap = False
                full_samhap_group = None
                for samhap_key_tuple in JIJI_SAMHAP_RULES.keys():
                    if wangji in samhap_key_tuple and (i_ji in samhap_key_tuple and j_ji in samhap_key_tuple):
                        full_samhap_group = samhap_key_tuple; break
                if full_samhap_group and full_samhap_group in found_samhap_banhap_combinations: is_part_of_samhap = True
                if not is_part_of_samhap:
                    banhap_result_str = f"{pos_str} â†’ {wangji} ê¸°ì¤€ ë°˜í•© ({JIJI_SAMHAP_RULES.get(full_samhap_group, 'êµ­ í˜•ì„±')})"
                    # Check if a similar string already exists to prevent duplicates from different orderings
                    is_already_added_as_banhap = False
                    for existing_item in results["ì§€ì§€ì‚¼í•©"]:
                         if f"{PILLAR_NAMES_KOR_SHORT[j_idx]}ì§€({j_ji}) + {PILLAR_NAMES_KOR_SHORT[i_idx]}ì§€({i_ji})" in existing_item and "ë°˜í•©" in existing_item:
                             is_already_added_as_banhap = True
                             break
                    if not is_already_added_as_banhap and not any(banhap_result_str == item for item in results["ì§€ì§€ì‚¼í•©"]):
                         results["ì§€ì§€ì‚¼í•©"].append(banhap_result_str)
                break
    for jahyeong_char in JAHYEONG_CHARS:
        count = jis.count(jahyeong_char)
        if count >= 2:
            positions = [f"{PILLAR_NAMES_KOR_SHORT[i]}ì§€({jis[i]})" for i, ji_val in enumerate(jis) if ji_val == jahyeong_char]
            results["í˜•ì‚´(åˆ‘æ®º)"].append(f"{', '.join(positions)} ({jahyeong_char}{jahyeong_char}) â†’ ìí˜•(è‡ªåˆ‘)")
    return results

def get_hap_chung_detail_explanation(found_interactions_dict):
    if not found_interactions_dict or not any(v for v in found_interactions_dict.values()):
        return "<p>íŠ¹ë³„íˆ ë‘ë“œëŸ¬ì§€ëŠ” í•©ì¶©í˜•í•´íŒŒì˜ ê´€ê³„ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹„êµì  ì•ˆì •ì ì¸ êµ¬ì¡°ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>"
    explanation_parts = []
    interaction_explanations = {
        "ì²œê°„í•©": "ì •ì‹ ì , ì‚¬íšŒì  ê´€ê³„ì—ì„œì˜ ì—°í•©, ë³€í™” ë˜ëŠ” ìƒˆë¡œìš´ ê¸°ìš´ì˜ ìƒì„± ê°€ëŠ¥ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.",
        "ì§€ì§€ìœ¡í•©": "ê°œì¸ì ì¸ ê´€ê³„, ì• ì •, ë˜ëŠ” ë¹„ë°€ìŠ¤ëŸ¬ìš´ í•©ì˜ë‚˜ ë‚´ë¶€ì ì¸ ê²°ì†ì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ì§€ì§€ì‚¼í•©": "ê°•ë ¥í•œ ì‚¬íšŒì  í•©ìœ¼ë¡œ, íŠ¹ì • ëª©í‘œë¥¼ í–¥í•œ ê°•ë ¥í•œ ì¶”ì§„ë ¥ì´ë‚˜ ì„¸ë ¥ í˜•ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (ë°˜í•© í¬í•¨)",
        "ì§€ì§€ë°©í•©": "ê°€ì¡±, ì§€ì—­, ë™ë£Œ ë“± í˜ˆì—°ì´ë‚˜ ì§€ì—°ì— ê¸°ë°˜í•œ ê°•í•œ ê²°ì†ë ¥ì´ë‚˜ ì„¸ë ¥ í™•ì¥ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
        "ì²œê°„ì¶©": "ìƒê°ì˜ ì¶©ëŒ, ê°€ì¹˜ê´€ì˜ ëŒ€ë¦½, ë˜ëŠ” ì™¸ë¶€ í™˜ê²½ìœ¼ë¡œë¶€í„°ì˜ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”ë‚˜ ìê·¹, ì •ì‹ ì  ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ì•”ì‹œí•©ë‹ˆë‹¤.",
        "ì§€ì§€ì¶©": "í˜„ì‹¤ì ì¸ ë³€í™”, ì´ë™, ê´€ê³„ì˜ ë‹¨ì ˆ ë˜ëŠ” ìƒˆë¡œìš´ ì‹œì‘, ê±´ê°•ìƒì˜ ì£¼ì˜ ë“±ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ë™ì ì¸ ì‚¬ê±´ì˜ ë°œìƒ ê°€ëŠ¥ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
        "í˜•ì‚´(åˆ‘æ®º)": "ì¡°ì •, ê°ˆë“±, ë²•ì  ë¬¸ì œ, ìˆ˜ìˆ , ë°°ì‹ , ë˜ëŠ” ë‚´ì  ê°ˆë“±ê³¼ ì„±ì¥í†µ ë“±ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë•Œë¡œëŠ” ì •êµí•¨ì´ë‚˜ ì „ë¬¸ì„±ì„ ìš”êµ¬í•˜ëŠ” ì¼ê³¼ë„ ê´€ë ¨ë©ë‹ˆë‹¤.",
        "í•´ì‚´(å®³æ®º)": "ê´€ê³„ì—ì„œì˜ ë°©í•´, ì§ˆíˆ¬, ì˜¤í•´, ë˜ëŠ” ê±´ê°•ìƒì˜ ë¬¸ì œ(ì£¼ë¡œ ë§Œì„±ì ) ë“±ì„ ì•”ì‹œí•©ë‹ˆë‹¤. ì˜ˆê¸°ì¹˜ ì•Šì€ ì†ì‹¤ì´ë‚˜ ì–´ë ¤ì›€ì„ ê²ªì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "íŒŒì‚´(ç ´æ®º)": "ê¹¨ì§, ë¶„ë¦¬, ì†ìƒ, ê³„íšì˜ ì°¨ì§ˆ, ê´€ê³„ì˜ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë‹¨ì ˆ ë“±ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì˜ ê²ƒì´ ê¹¨ì§€ê³  ìƒˆë¡œì›Œì§€ëŠ” ê³¼ì •ì„ ì˜ë¯¸í•˜ê¸°ë„ í•©ë‹ˆë‹¤."
    }
    for key, found_list in found_interactions_dict.items():
        if found_list:
            desc = interaction_explanations.get(key)
            if desc: explanation_parts.append(f"<li><strong>{key}:</strong> {desc}</li>")
    if not explanation_parts: return "<p>êµ¬ì²´ì ì¸ í•©ì¶©í˜•í•´íŒŒ ê´€ê³„ì— ëŒ€í•œ ì„¤ëª…ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</p>"
    return "<ul style='list-style-type: disc; margin-left: 20px; padding-left: 0;'>" + "".join(explanation_parts) + "</ul>"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì£¼ìš” ì‹ ì‚´(ç¥ç…) ë¶„ì„ìš© ìƒìˆ˜ ë° í•¨ìˆ˜ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHEONEULGWIIN_MAP = {
    "ê°‘": ["ì¶•", "ë¯¸"], "ì„": ["ì", "ì‹ "], "ë³‘": ["í•´", "ìœ "], "ì •": ["í•´", "ìœ "],
    "ë¬´": ["ì¶•", "ë¯¸"], "ê¸°": ["ì", "ì‹ "], "ê²½": ["ì¶•", "ë¯¸", "ì¸", "ì˜¤"],
    "ì‹ ": ["ì¸", "ì˜¤"], "ì„": ["ì‚¬", "ë¬˜"], "ê³„": ["ì‚¬", "ë¬˜"]
}
MUNCHANGGWIIN_MAP = {
    "ê°‘": "ì‚¬", "ì„": "ì˜¤", "ë³‘": "ì‹ ", "ì •": "ìœ ", "ë¬´": "ì‹ ",
    "ê¸°": "ìœ ", "ê²½": "í•´", "ì‹ ": "ì", "ì„": "ì¸", "ê³„": "ë¬˜"
}
DOHWASAL_MAP = {
    "í•´": "ì", "ë¬˜": "ì", "ë¯¸": "ì", "ì¸": "ë¬˜", "ì˜¤": "ë¬˜", "ìˆ ": "ë¬˜",
    "ì‚¬": "ì˜¤", "ìœ ": "ì˜¤", "ì¶•": "ì˜¤", "ì‹ ": "ìœ ", "ì": "ìœ ", "ì§„": "ìœ "
}
YEONGMASAL_MAP = {
    "í•´": "ì‚¬", "ë¬˜": "ì‚¬", "ë¯¸": "ì‚¬", "ì¸": "ì‹ ", "ì˜¤": "ì‹ ", "ìˆ ": "ì‹ ",
    "ì‚¬": "í•´", "ìœ ": "í•´", "ì¶•": "í•´", "ì‹ ": "ì¸", "ì": "ì¸", "ì§„": "ì¸"
}
HWAGAESAL_MAP = {
    "í•´": "ë¯¸", "ë¬˜": "ë¯¸", "ë¯¸": "ë¯¸", "ì¸": "ìˆ ", "ì˜¤": "ìˆ ", "ìˆ ": "ìˆ ",
    "ì‚¬": "ì¶•", "ìœ ": "ì¶•", "ì¶•": "ì¶•", "ì‹ ": "ì§„", "ì": "ì§„", "ì§„": "ì§„"
}
GOEGANGSAL_ILJU_LIST = ["ê²½ì§„", "ê²½ìˆ ", "ì„ì§„", "ì„ìˆ ", "ë¬´ì§„", "ë¬´ìˆ "]
BAEKHODAESAL_GANJI_LIST = ["ê°‘ì§„", "ì„ë¯¸", "ë³‘ìˆ ", "ì •ì¶•", "ë¬´ì§„", "ì„ìˆ ", "ê³„ì¶•"]
GWIMUNGWANSAL_PAIRS = [
    tuple(sorted(("ì", "ìœ "))), tuple(sorted(("ì¶•", "ì˜¤"))), tuple(sorted(("ì¸", "ë¯¸"))),
    tuple(sorted(("ë¬˜", "ì‹ "))), tuple(sorted(("ì§„", "í•´"))), tuple(sorted(("ì‚¬", "ìˆ ")))
]
PILLAR_NAMES_KOR = ["ë…„ì£¼", "ì›”ì£¼", "ì¼ì£¼", "ì‹œì£¼"]

def analyze_shinsal(saju_8char_details):
    ilgan_char = saju_8char_details["day_gan"]
    all_jis = [saju_8char_details["year_ji"], saju_8char_details["month_ji"], saju_8char_details["day_ji"], saju_8char_details["time_ji"]]
    pillar_ganjis_str = [
        saju_8char_details["year_gan"] + saju_8char_details["year_ji"],
        saju_8char_details["month_gan"] + saju_8char_details["month_ji"],
        saju_8char_details["day_gan"] + saju_8char_details["day_ji"],
        saju_8char_details["time_gan"] + saju_8char_details["time_ji"]
    ]
    ilju_ganji_str = pillar_ganjis_str[2]
    found_shinsals_set = set()

    if ilgan_char in CHEONEULGWIIN_MAP:
        for ji_idx, ji_char in enumerate(all_jis):
            if ji_char in CHEONEULGWIIN_MAP[ilgan_char]: found_shinsals_set.add(f"ì²œì„ê·€ì¸: ì¼ê°„({ilgan_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")
    if ilgan_char in MUNCHANGGWIIN_MAP:
        for ji_idx, ji_char in enumerate(all_jis):
            if ji_char == MUNCHANGGWIIN_MAP[ilgan_char]: found_shinsals_set.add(f"ë¬¸ì°½ê·€ì¸: ì¼ê°„({ilgan_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")

    yeonji_char = saju_8char_details["year_ji"]; ilji_char = saju_8char_details["day_ji"]
    dohwa_for_yeonji = DOHWASAL_MAP.get(yeonji_char); dohwa_for_ilji = DOHWASAL_MAP.get(ilji_char)
    for ji_idx, ji_char in enumerate(all_jis):
        if dohwa_for_yeonji and ji_char == dohwa_for_yeonji: found_shinsals_set.add(f"ë„í™”ì‚´: ì—°ì§€({yeonji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")
        if dohwa_for_ilji and ji_char == dohwa_for_ilji and (yeonji_char != ilji_char or dohwa_for_yeonji != dohwa_for_ilji): found_shinsals_set.add(f"ë„í™”ì‚´: ì¼ì§€({ilji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")

    yeokma_for_yeonji = YEONGMASAL_MAP.get(yeonji_char); yeokma_for_ilji = YEONGMASAL_MAP.get(ilji_char)
    for ji_idx, ji_char in enumerate(all_jis):
        if yeokma_for_yeonji and ji_char == yeokma_for_yeonji: found_shinsals_set.add(f"ì—­ë§ˆì‚´: ì—°ì§€({yeonji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")
        if yeokma_for_ilji and ji_char == yeokma_for_ilji and (yeonji_char != ilji_char or yeokma_for_yeonji != yeokma_for_ilji) : found_shinsals_set.add(f"ì—­ë§ˆì‚´: ì¼ì§€({ilji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")

    hwagae_for_yeonji = HWAGAESAL_MAP.get(yeonji_char); hwagae_for_ilji = HWAGAESAL_MAP.get(ilji_char)
    for ji_idx, ji_char in enumerate(all_jis):
        if hwagae_for_yeonji and ji_char == hwagae_for_yeonji: found_shinsals_set.add(f"í™”ê°œì‚´: ì—°ì§€({yeonji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")
        if hwagae_for_ilji and ji_char == hwagae_for_ilji and (yeonji_char != ilji_char or hwagae_for_yeonji != hwagae_for_ilji): found_shinsals_set.add(f"í™”ê°œì‚´: ì¼ì§€({ilji_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")

    if ilgan_char in YANGIN_JI_MAP:
        for ji_idx, ji_char in enumerate(all_jis):
            if ji_char == YANGIN_JI_MAP[ilgan_char]: found_shinsals_set.add(f"ì–‘ì¸ì‚´: ì¼ê°„({ilgan_char}) ê¸°ì¤€ {PILLAR_NAMES_KOR_SHORT[ji_idx]}ì§€({ji_char})")
    if ilju_ganji_str in GOEGANGSAL_ILJU_LIST: found_shinsals_set.add(f"ê´´ê°•ì‚´: ì¼ì£¼({ilju_ganji_str})")
    for pillar_idx, current_pillar_ganji_str in enumerate(pillar_ganjis_str):
        if current_pillar_ganji_str in BAEKHODAESAL_GANJI_LIST: found_shinsals_set.add(f"ë°±í˜¸ëŒ€ì‚´: {PILLAR_NAMES_KOR[pillar_idx]}({current_pillar_ganji_str})")
    for (i_idx, i_ji), (j_idx, j_ji) in itertools.combinations(list(enumerate(all_jis)), 2):
        pair_sorted = tuple(sorted((i_ji, j_ji)))
        if pair_sorted in GWIMUNGWANSAL_PAIRS: found_shinsals_set.add(f"ê·€ë¬¸ê´€ì‚´: {PILLAR_NAMES_KOR_SHORT[i_idx]}ì§€({i_ji}) + {PILLAR_NAMES_KOR_SHORT[j_idx]}ì§€({j_ji})")

    try:
        ilgan_idx = GAN.index(ilgan_char); ilji_idx_val = JI.index(ilji_char)
        ilju_gapja_idx = -1
        for i in range(60):
            if GAN[i % 10] == ilgan_char and JI[i % 12] == ilji_char: ilju_gapja_idx = i; break
        if ilju_gapja_idx != -1:
            gongmang_jis = JI[(ilju_gapja_idx + 10) % 12], JI[(ilju_gapja_idx + 11) % 12]
            found_shinsals_set.add(f"ê³µë§(ç©ºäº¡): ì¼ì£¼({ilju_ganji_str}) ê¸°ì¤€ {gongmang_jis[0]}, {gongmang_jis[1]} ê³µë§")
            found_in_pillars = []
            for ji_idx, ji_char_in_saju in enumerate(all_jis):
                if ji_char_in_saju in gongmang_jis: found_in_pillars.append(f"{PILLAR_NAMES_KOR[ji_idx]}ì˜ {ji_char_in_saju}")
            if found_in_pillars: found_shinsals_set.add(f"  â”” ({', '.join(found_in_pillars)})ê°€ ê³µë§ì— í•´ë‹¹í•©ë‹ˆë‹¤.")
    except (IndexError, ValueError): pass
    return sorted(list(found_shinsals_set))

def get_shinsal_detail_explanation(found_shinsals_list):
    if not found_shinsals_list: return "<p>íŠ¹ë³„íˆ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ìš” ì‹ ì‚´ì´ ì—†ìŠµë‹ˆë‹¤.</p>"
    explanation_parts = []
    main_shinsal_explanations = {
        "ì²œì„ê·€ì¸": "ì–´ë ¤ìš¸ ë•Œ ê·€ì¸ì˜ ë„ì›€ì„ ë°›ê±°ë‚˜ ìœ„ê¸°ë¥¼ ë„˜ê¸°ëŠ” í–‰ìš´ì´ ë”°ë¥´ëŠ” ê¸¸ì„± ì¤‘ì˜ ê¸¸ì„±ì…ë‹ˆë‹¤.",
        "ë¬¸ì°½ê·€ì¸": "í•™ë¬¸, ì§€í˜œ, ì´ëª…í•¨ì„ ë‚˜íƒ€ë‚´ë©° ê¸€ì¬ì£¼ë‚˜ ì‹œí—˜ìš´ ë“±ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ë„í™”ì‚´": "ë§¤ë ¥, ì¸ê¸°, ì˜ˆìˆ ì  ê°ê°ì„ ì˜ë¯¸í•˜ë©°, ì´ì„±ì—ê²Œ ì¸ê¸°ê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‚˜ ë•Œë¡œëŠ” êµ¬ì„¤ì„ ì¡°ì‹¬í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ì—­ë§ˆì‚´": "í™œë™ì„±, ì´ë™, ë³€í™”, ì—¬í–‰, í•´ì™¸ì™€ì˜ ì¸ì—° ë“±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. í•œ ê³³ì— ì •ì°©í•˜ê¸°ë³´ë‹¤ ë³€í™”ë¥¼ ì¶”êµ¬í•˜ëŠ” ì„±í–¥ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "í™”ê°œì‚´": "ì˜ˆìˆ , ì¢…êµ, í•™ë¬¸, ì² í•™ ë“± ì •ì‹ ì„¸ê³„ì™€ ê´€ë ¨ëœ ë¶„ì•¼ì— ì¬ëŠ¥ì´ë‚˜ ì¸ì—°ì´ ê¹Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë•Œë¡œ ê³ ë…ê°ì„ ëŠë¼ê¸°ë„ í•©ë‹ˆë‹¤.",
        "ì–‘ì¸ì‚´": "ê°•í•œ ì—ë„ˆì§€, ì¹´ë¦¬ìŠ¤ë§ˆ, ë…ë¦½ì‹¬, ê²½ìŸì‹¬ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìˆœíƒ„í•  ë•ŒëŠ” í° ì„±ì·¨ë¥¼ ì´ë£¨ì§€ë§Œ, ìš´ì´ ë‚˜ì  ë•ŒëŠ” ê³¼ê²©í•¨ì´ë‚˜ ì‚¬ê±´ì‚¬ê³ ë¥¼ ì¡°ì‹¬í•´ì•¼ í•©ë‹ˆë‹¤.",
        "ê´´ê°•ì‚´": "ë§¤ìš° ê°•í•œ ê¸°ìš´ê³¼ ë¦¬ë”ì‹­, ì´ëª…í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ê·¹ë‹¨ì ì¸ ì„±í–¥ì´ë‚˜ ê³ ì§‘ì„ ì£¼ì˜í•´ì•¼ í•˜ë©°, í° ì¸ë¬¼ì´ ë  ê°€ëŠ¥ì„±ë„ ìˆìŠµë‹ˆë‹¤.",
        "ë°±í˜¸ëŒ€ì‚´": "ê°•í•œ ê¸°ìš´ìœ¼ë¡œ ì¸í•´ ê¸‰ì‘ìŠ¤ëŸ¬ìš´ ì‚¬ê±´, ì‚¬ê³ , ì§ˆë³‘ ë“±ì„ ê²½í—˜í•  ìˆ˜ ìˆìŒì„ ì•”ì‹œí•˜ë¯€ë¡œ í‰ì†Œ ê±´ê°•ê³¼ ì•ˆì „ì— ìœ ì˜í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.",
        "ê·€ë¬¸ê´€ì‚´": "ì˜ˆë¯¼í•¨, ì§ê´€ë ¥, ì˜ê°, ë…íŠ¹í•œ ì •ì‹ ì„¸ê³„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë•Œë¡œëŠ” ì‹ ê²½ê³¼ë¯¼, ë³€ë•, ì§‘ì°© ë“±ìœ¼ë¡œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì–´ ë§ˆìŒì˜ ì•ˆì •ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
        "ê³µë§": "í•´ë‹¹ ê¸€ìì˜ ì˜í–¥ë ¥ì´ ì•½í™”ë˜ê±°ë‚˜ ê³µí—ˆí•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì •ì‹ ì ì¸ í™œë™, ì¢…êµ, ì² í•™ ë“±ì— ê´€ì‹¬ì„ ë‘ê±°ë‚˜, ì˜ˆìƒ ë°–ì˜ ê²°ê³¼ë‚˜ ë³€í™”ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    }
    added_explanations_keys = set()
    for shinsal_item_str in found_shinsals_list:
        for shinsal_key, desc in main_shinsal_explanations.items():
            if shinsal_key in shinsal_item_str and shinsal_key not in added_explanations_keys:
                explanation_parts.append(f"<li><strong>{shinsal_key}:</strong> {desc}</li>")
                added_explanations_keys.add(shinsal_key)
    if not explanation_parts: return "<p>ë°œê²¬ëœ ì‹ ì‚´ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì„¤ëª…ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</p>"
    return "<ul style='list-style-type: disc; margin-left: 20px; padding-left: 0;'>" + "".join(explanation_parts) + "</ul>"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìš©ì‹ /ê¸°ì‹  ë¶„ì„ìš© ìƒìˆ˜ ë° í•¨ìˆ˜ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OHENG_HELPER_MAP = {"ëª©": "ìˆ˜", "í™”": "ëª©", "í† ": "í™”", "ê¸ˆ": "í† ", "ìˆ˜": "ê¸ˆ"}
OHENG_PRODUCES_MAP = {"ëª©": "í™”", "í™”": "í† ", "í† ": "ê¸ˆ", "ê¸ˆ": "ìˆ˜", "ìˆ˜": "ëª©"}
OHENG_CONTROLS_MAP = {"ëª©": "í† ", "í™”": "ê¸ˆ", "í† ": "ìˆ˜", "ê¸ˆ": "ëª©", "ìˆ˜": "í™”"}
OHENG_IS_CONTROLLED_BY_MAP = {"ëª©": "ê¸ˆ", "í™”": "ìˆ˜", "í† ": "ëª©", "ê¸ˆ": "í™”", "ìˆ˜": "í† "}

def determine_yongshin_gishin_simplified(day_gan_char, shinkang_status_str):
    ilgan_ohaeng = GAN_TO_OHENG.get(day_gan_char)
    if not ilgan_ohaeng: return {"yongshin": [], "gishin": [], "html": "<p>ì¼ê°„ì˜ ì˜¤í–‰ì„ ì•Œ ìˆ˜ ì—†ì–´ ìš©ì‹ /ê¸°ì‹ ì„ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>"}
    yongshin_candidates = []; gishin_candidates = []
    sikìƒ_ohaeng = OHENG_PRODUCES_MAP.get(ilgan_ohaeng); jaeì„±_ohaeng = OHENG_CONTROLS_MAP.get(ilgan_ohaeng)
    gwanì„±_ohaeng = OHENG_IS_CONTROLLED_BY_MAP.get(ilgan_ohaeng); inì„±_ohaeng = OHENG_HELPER_MAP.get(ilgan_ohaeng)
    biê²_ohaeng = ilgan_ohaeng
    if "ì‹ ê°•" in shinkang_status_str:
        if sikìƒ_ohaeng: yongshin_candidates.append(sikìƒ_ohaeng)
        if jaeì„±_ohaeng: yongshin_candidates.append(jaeì„±_ohaeng)
        if gwanì„±_ohaeng: yongshin_candidates.append(gwanì„±_ohaeng)
        if inì„±_ohaeng: gishin_candidates.append(inì„±_ohaeng)
        if biê²_ohaeng: gishin_candidates.append(biê²_ohaeng)
    elif "ì‹ ì•½" in shinkang_status_str:
        if inì„±_ohaeng: yongshin_candidates.append(inì„±_ohaeng)
        if biê²_ohaeng: yongshin_candidates.append(biê²_ohaeng)
        if sikìƒ_ohaeng: gishin_candidates.append(sikìƒ_ohaeng)
        if jaeì„±_ohaeng: gishin_candidates.append(jaeì„±_ohaeng)
        if gwanì„±_ohaeng: gishin_candidates.append(gwanì„±_ohaeng)
    elif "ì¤‘í™”" in shinkang_status_str:
        return {"yongshin": [], "gishin": [], "html": "<p>ì¤‘í™” ì‚¬ì£¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. ì´ ê²½ìš° íŠ¹ì • ì˜¤í–‰ì„ ìš©ì‹ ì´ë‚˜ ê¸°ì‹ ìœ¼ë¡œ ì—„ê²©íˆ êµ¬ë¶„í•˜ê¸°ë³´ë‹¤ëŠ”, ì‚¬ì£¼ ì „ì²´ì˜ ê· í˜•ê³¼ ì¡°í™”ë¥¼ ìœ ì§€í•˜ê³  ëŒ€ìš´ì˜ íë¦„ì— ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë•Œë¡œëŠ” ì‚¬ì£¼ì— ë¶€ì¡±í•˜ê±°ë‚˜ ê³ ë¦½ëœ ì˜¤í–‰ì„ ë³´ì¶©í•˜ëŠ” ë°©í–¥ì„ ê³ ë ¤í•˜ê¸°ë„ í•©ë‹ˆë‹¤.</p>"}
    else: return {"yongshin": [], "gishin": [], "html": "<p>ì¼ê°„ì˜ ê°•ì•½ ìƒíƒœê°€ ëª…í™•í•˜ì§€ ì•Šì•„ ìš©ì‹ /ê¸°ì‹ ì„ íŒë‹¨í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.</p>"}
    unique_yongshin = sorted(list(set(yongshin_candidates))); unique_gishin = sorted(list(set(gishin_candidates)))
    html_parts = []
    if unique_yongshin: html_parts.append(f"<p>ìœ ë ¥í•œ ìš©ì‹ (å–œç¥) í›„ë³´ ì˜¤í–‰: {', '.join([f'<span style=\\'color:#15803d; font-weight:bold;\\'>{o}({OHENG_TO_HANJA.get(o, "")})</span>' for o in unique_yongshin])}</p>")
    else: html_parts.append("<p>ìš©ì‹ (å–œç¥)ìœ¼ë¡œ íŠ¹ì •í•  ë§Œí•œ ì˜¤í–‰ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. (ì¤‘í™” ì‚¬ì£¼ ì™¸)</p>")
    if unique_gishin: html_parts.append(f"<p>ì£¼ì˜ê°€ í•„ìš”í•œ ê¸°ì‹ (å¿Œç¥) í›„ë³´ ì˜¤í–‰: {', '.join([f'<span style=\\'color:#b91c1c; font-weight:bold;\\'>{o}({OHENG_TO_HANJA.get(o, "")})</span>' for o in unique_gishin])}</p>")
    else: html_parts.append("<p>íŠ¹ë³„íˆ ê¸°ì‹ (å¿Œç¥)ìœ¼ë¡œ ê°•í•˜ê²Œ ì‘ìš©í•  ë§Œí•œ ì˜¤í–‰ì´ ë‘ë“œëŸ¬ì§€ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>")
    return {"yongshin": unique_yongshin, "gishin": unique_gishin, "html": "".join(html_parts)}

def get_gaewoon_tips_html(yongshin_list):
    if not yongshin_list: return ""
    tips_html = "<h5 style='color: #047857; margin-top: 0.8rem; margin-bottom: 0.3rem; font-size:1em;'>ğŸ€ ê°„ë‹¨ ê°œìš´ë²• (ìš©ì‹  í™œìš©)</h5><ul style='list-style:none; padding-left:0; font-size:0.9em;'>"
    gaewoon_tips_data = {
        "ëª©": "<li><strong style='color:#15803d;'>ëª©(æœ¨) ìš©ì‹ :</strong> ë™ìª½ ë°©í–¥, í‘¸ë¥¸ìƒ‰/ì´ˆë¡ìƒ‰ ê³„ì—´ ì•„ì´í…œ í™œìš©. ìˆ²ì´ë‚˜ ê³µì› ì‚°ì±…, ì‹ë¬¼ í‚¤ìš°ê¸°, êµìœ¡/ë¬¸í™”/ê¸°íš ê´€ë ¨ í™œë™.</li>",
        "í™”": "<li><strong style='color:#15803d;'>í™”(ç«) ìš©ì‹ :</strong> ë‚¨ìª½ ë°©í–¥, ë¶‰ì€ìƒ‰/ë¶„í™ìƒ‰/ë³´ë¼ìƒ‰ ê³„ì—´ ì•„ì´í…œ í™œìš©. ë°ê³  ë”°ëœ»í•œ í™˜ê²½ ì¡°ì„±, ì˜ˆì²´ëŠ¥/ë°©ì†¡/ì¡°ëª…/ì—´ì •ì ì¸ í™œë™.</li>",
        "í† ": "<li><strong style='color:#15803d;'>í† (åœŸ) ìš©ì‹ :</strong> ì¤‘ì•™(ê±°ì£¼ì§€ ì¤‘ì‹¬), ë…¸ë€ìƒ‰/í™©í† ìƒ‰/ë² ì´ì§€ìƒ‰ ê³„ì—´ ì•„ì´í…œ í™œìš©. ì•ˆì •ì ì´ê³  í¸ì•ˆí•œ í™˜ê²½, ëª…ìƒ, ì‹ ìš©ì„ ì¤‘ì‹œí•˜ëŠ” í™œë™, ë“±ì‚°.</li>",
        "ê¸ˆ": "<li><strong style='color:#15803d;'>ê¸ˆ(é‡‘) ìš©ì‹ :</strong> ì„œìª½ ë°©í–¥, í°ìƒ‰/ì€ìƒ‰/ê¸ˆìƒ‰ ê³„ì—´ ì•„ì´í…œ í™œìš©. ë‹¨ë‹¨í•˜ê³  ì •ëˆëœ í™˜ê²½, ê¸ˆì† ì•¡ì„¸ì„œë¦¬, ê²°ë‹¨ë ¥ê³¼ ì˜ë¦¬ë¥¼ ì§€í‚¤ëŠ” í™œë™, ì•…ê¸° ì—°ì£¼.</li>",
        "ìˆ˜": "<li><strong style='color:#15803d;'>ìˆ˜(æ°´) ìš©ì‹ :</strong> ë¶ìª½ ë°©í–¥, ê²€ì€ìƒ‰/íŒŒë€ìƒ‰/íšŒìƒ‰ ê³„ì—´ ì•„ì´í…œ í™œìš©. ë¬¼ê°€ë‚˜ ì¡°ìš©í•˜ê³  ì°¨ë¶„í•œ í™˜ê²½, ì§€í˜œë¥¼ í™œìš©í•˜ëŠ” í™œë™, ëª…ìƒì´ë‚˜ ì¶©ë¶„í•œ íœ´ì‹.</li>"
    }
    for yongshin_ohaeng in yongshin_list: tips_html += gaewoon_tips_data.get(yongshin_ohaeng, f"<li>{yongshin_ohaeng}({OHENG_TO_HANJA.get(yongshin_ohaeng,'')}) ìš©ì‹ ì— ëŒ€í•œ ê°œìš´ë²• ì •ë³´ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</li>")
    tips_html += "</ul><p style='font-size:0.8rem; color:#555; margin-top:0.5rem;'>* ìœ„ ë‚´ìš©ì€ ì¼ë°˜ì ì¸ ê°œìš´ë²•ì´ë©°, ê°œì¸ì˜ ì „ì²´ ì‚¬ì£¼ êµ¬ì¡°ì™€ ìƒí™©ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³ ìš©ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.</p>"
    return tips_html

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜¤í–‰ ë° ì‹­ì‹  ì„¸ë ¥ ê³„ì‚° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def calculate_ohaeng_sipshin_strengths(saju_8char_details):
    day_master_gan = saju_8char_details["day_gan"]
    chars_to_analyze = [
        (saju_8char_details["year_gan"], "ì—°ê°„"), (saju_8char_details["year_ji"], "ì—°ì§€"),
        (saju_8char_details["month_gan"], "ì›”ê°„"), (saju_8char_details["month_ji"], "ì›”ì§€"),
        (saju_8char_details["day_gan"], "ì¼ê°„"), (saju_8char_details["day_ji"], "ì¼ì§€"),
        (saju_8char_details["time_gan"], "ì‹œê°„"), (saju_8char_details["time_ji"], "ì‹œì§€")
    ]
    ohaeng_strengths = {oheng: 0.0 for oheng in OHENG_ORDER}
    sipshin_strengths = {sipshin: 0.0 for sipshin in SIPSHIN_ORDER}
    def get_sipshin(dm_gan, other_gan):
        return SIPSHIN_MAP.get(dm_gan, {}).get(other_gan)

    for char_val, position_key in chars_to_analyze:
        weight = POSITIONAL_WEIGHTS.get(position_key, 0.0)
        is_gan = "ê°„" in position_key
        if is_gan:
            ohaeng = GAN_TO_OHENG.get(char_val)
            if ohaeng: ohaeng_strengths[ohaeng] += weight
            sipshin = get_sipshin(day_master_gan, char_val)
            if sipshin: sipshin_strengths[sipshin] += weight
        else:
            if char_val in JIJI_JANGGAN:
                for janggan_char, proportion in JIJI_JANGGAN[char_val].items():
                    ohaeng = GAN_TO_OHENG.get(janggan_char)
                    if ohaeng: ohaeng_strengths[ohaeng] += weight * proportion
                    sipshin = get_sipshin(day_master_gan, janggan_char)
                    if sipshin: sipshin_strengths[sipshin] += weight * proportion
    for o in OHENG_ORDER: ohaeng_strengths[o] = round(ohaeng_strengths[o], 1)
    for s in SIPSHIN_ORDER: sipshin_strengths[s] = round(sipshin_strengths[s], 1)
    return ohaeng_strengths, sipshin_strengths

def get_ohaeng_summary_explanation(ohaeng_counts):
    explanation = "ì˜¤í–‰ ë¶„í¬ëŠ” ì‚¬ì£¼ì˜ ì—ë„ˆì§€ ê· í˜•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. "
    if not ohaeng_counts: return explanation + "ì˜¤í–‰ ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    sorted_ohaeng = sorted(ohaeng_counts.items(), key=lambda item: item[1], reverse=True)
    threshold = 1.5 # Example threshold
    if sorted_ohaeng and sorted_ohaeng[0][1] > threshold * 1.5 :
        explanation += f"íŠ¹íˆ {sorted_ohaeng[0][0]}(ì´)ê°€ {sorted_ohaeng[0][1]}ì ìœ¼ë¡œ ê°€ì¥ ê°•í•œ ê¸°ìš´ì„ ê°€ì§‘ë‹ˆë‹¤. "
    if sorted_ohaeng and sorted_ohaeng[-1][1] < threshold / 1.5 and sorted_ohaeng[-1][1] < sorted_ohaeng[0][1] / 2:
         explanation += f"ë°˜ë©´, {sorted_ohaeng[-1][0]}(ì´)ê°€ {sorted_ohaeng[-1][1]}ì ìœ¼ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ í¸ì…ë‹ˆë‹¤. "
    explanation += "ì „ì²´ì ì¸ ê· í˜•ê³¼ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
    return explanation

def get_sipshin_summary_explanation(sipshin_counts, day_master_gan):
    explanation = "ì‹­ì‹ ì€ ì¼ê°„(ë‚˜)ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ê¸€ìì™€ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì‚¬íšŒì  ê´€ê³„, ì„±í–¥, ì¬ëŠ¥ ë“±ì„ ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
    threshold = 1.5
    strong_sibsins = [f"{s_name}({sipshin_counts.get(s_name, 0.0)})" for s_name in SIPSHIN_ORDER if sipshin_counts.get(s_name, 0.0) >= threshold]
    if strong_sibsins:
        explanation += f"ì´ ì‚¬ì£¼ì—ì„œëŠ” {', '.join(strong_sibsins)}ì˜ ì˜í–¥ë ¥ì´ ë‘ë“œëŸ¬ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        temp_explanations = []
        for s_info in strong_sibsins:
            s_name = s_info.split('(')[0]
            if s_name in ["ë¹„ê²¬", "ê²ì¬"]: temp_explanations.append("ì£¼ì²´ì„±/ë…ë¦½ì‹¬/ê²½ìŸì‹¬")
            elif s_name in ["ì‹ì‹ ", "ìƒê´€"]: temp_explanations.append("í‘œí˜„ë ¥/ì°½ì˜ë ¥/ê¸°ìˆ  ê´€ë ¨ ì¬ëŠ¥")
            elif s_name in ["í¸ì¬", "ì •ì¬"]: temp_explanations.append("í˜„ì‹¤ê°ê°/ì¬ë¬¼ìš´ìš©/í™œë™ì„±")
            elif s_name in ["í¸ê´€", "ì •ê´€"]: temp_explanations.append("ì±…ì„ê°/ëª…ì˜ˆ/ì¡°ì§ ì ì‘ë ¥")
            elif s_name in ["í¸ì¸", "ì •ì¸"]: temp_explanations.append("í•™ë¬¸/ìˆ˜ìš©ì„±/ì§ê´€ë ¥")
        unique_explanations = list(set(temp_explanations))
        if unique_explanations: explanation += f" ì´ëŠ” {', '.join(unique_explanations)} ë“±ì´ ë°œë‹¬í–ˆì„ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•©ë‹ˆë‹¤. "
    else: explanation += "íŠ¹ë³„íˆ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹˜ê¸°ë³´ë‹¤ëŠ” ì—¬ëŸ¬ ì‹­ì‹ ì˜ íŠ¹ì„±ì´ ë¹„êµì  ê· í˜• ìˆê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
    explanation += "ê° ì‹­ì‹ ì˜ ê¸ì •ì ì¸ ë©´ì„ ì˜ ë°œíœ˜í•˜ê³  ë³´ì™„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
    return explanation

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ì ˆì…ì¼ ë°ì´í„° ë¡œë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner=False)
def load_solar_terms(file_name: str):
    if not os.path.exists(file_name):
        st.error(f"`{file_name}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None
    try: df = pd.read_excel(file_name, engine='openpyxl')
    except Exception as e: st.error(f"ì—‘ì…€ íŒŒì¼('{file_name}')ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. 'openpyxl' íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."); return None
    term_dict = {}
    required_excel_cols = ["ì ˆê¸°", "iso_datetime"]
    if not all(col in df.columns for col in required_excel_cols): st.error(f"ì—‘ì…€ íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼({required_excel_cols})ì´ ì—†ìŠµë‹ˆë‹¤."); return None
    for _, row in df.iterrows():
        term = str(row["ì ˆê¸°"]).strip(); dt_val = row["iso_datetime"]
        if isinstance(dt_val, str): dt = pd.to_datetime(dt_val, errors="coerce")
        elif isinstance(dt_val, datetime): dt = pd.Timestamp(dt_val)
        elif isinstance(dt_val, pd.Timestamp): dt = dt_val
        else: st.warning(f"'{term}'ì˜ 'iso_datetime' ê°’ ('{dt_val}')ì„ datetimeìœ¼ë¡œ ë³€í™˜ ë¶ˆê°€."); continue
        if pd.isna(dt): st.warning(f"'{term}'ì˜ 'iso_datetime' ê°’ ('{row['iso_datetime']}')ì„ íŒŒì‹± ë¶ˆê°€."); continue
        term_dict.setdefault(dt.year, {})[term] = dt
    if not term_dict: st.warning("ì ˆê¸° ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆê±°ë‚˜ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."); return None
    return term_dict

solar_data = load_solar_terms(FILE_NAME)
if solar_data is None: st.stop()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ì‚¬ì£¼/ìš´ì„¸ ê³„ì‚° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_saju_year(birth_dt, solar_data_dict):
    year = birth_dt.year; ipchun_data = solar_data_dict.get(year, {}); ipchun = ipchun_data.get("ì…ì¶˜")
    return year - 1 if (ipchun and birth_dt < ipchun) else year

def get_ganji_from_index(idx): return GAN[idx % 10] + JI[idx % 12]
def get_year_ganji(saju_year): idx = (saju_year - 4 + 60) % 60; return get_ganji_from_index(idx), GAN[idx % 10], JI[idx % 12]

def get_month_ganji(year_gan_char, birth_dt, solar_data_dict):
    saju_year_for_month = get_saju_year(birth_dt, solar_data_dict)
    terms_this_saju_year = solar_data_dict.get(saju_year_for_month, {})
    terms_prev_saju_year = solar_data_dict.get(saju_year_for_month - 1, {})
    governing_term_name = None
    sorted_terms_this_year = sorted([(name, dt) for name, dt in terms_this_saju_year.items() if name in SAJU_MONTH_TERMS_ORDER], key=lambda x: x[1])
    for name, dt in sorted_terms_this_year:
        if birth_dt >= dt: governing_term_name = name
        else: break
    if not governing_term_name:
        sorted_prev_year_winter_terms = sorted([(name, dt) for name, dt in terms_prev_saju_year.items() if name in ["ì†Œí•œ", "ëŒ€ì„¤"]], key=lambda x: x[1], reverse=True)
        for name, dt in sorted_prev_year_winter_terms:
            if birth_dt >= dt: governing_term_name = name; break
    if not governing_term_name: return "ì˜¤ë¥˜(ì›”ì£¼ì ˆê¸°)", "", ""
    try: branch_idx_in_sason = SAJU_MONTH_TERMS_ORDER.index(governing_term_name); month_ji = SAJU_MONTH_BRANCHES[branch_idx_in_sason]
    except ValueError: return f"ì˜¤ë¥˜({governing_term_name}ì—†ìŒ)", "", ""
    yg_idx = GAN.index(year_gan_char); start_map = {0:2,5:2, 1:4,6:4, 2:6,7:6, 3:8,8:8, 4:0,9:0}
    start_gan_idx_for_in_month = start_map.get(yg_idx)
    if start_gan_idx_for_in_month is None: return "ì˜¤ë¥˜(ì—°ê°„->ì›”ê°„ë§µ)", "", ""
    month_order_idx = SAJU_MONTH_BRANCHES.index(month_ji)
    month_gan = GAN[(start_gan_idx_for_in_month + month_order_idx) % 10]
    return month_gan + month_ji, month_gan, month_ji

def date_to_jd(year, month, day):
    y = year; m = month
    if m <= 2: y -= 1; m += 12
    a = math.floor(y / 100); b = 2 - a + math.floor(a / 4)
    return int(math.floor(365.25 * (y + 4716)) + math.floor(30.6001 * (m + 1)) + day + b - 1524)

def get_day_ganji(year, month, day):
    jd = date_to_jd(year, month, day)
    day_stem_idx = (jd + 9) % 10; day_branch_idx = (jd + 1) % 12
    return GAN[day_stem_idx] + JI[day_branch_idx], GAN[day_stem_idx], JI[day_branch_idx]

def get_time_ganji(day_gan_char, hour, minute):
    cur_time_float = hour + minute/60.0; siji_char, siji_order_idx = None, -1
    for (sh,sm),(eh,em), ji_name, order_idx in TIME_BRANCH_MAP:
        start_float = sh + sm/60.0; end_float = eh + em/60.0
        if ji_name == "ì":
            if cur_time_float >= start_float or cur_time_float <= end_float: siji_char,siji_order_idx=ji_name,order_idx;break
        elif start_float <= cur_time_float < end_float: siji_char,siji_order_idx=ji_name,order_idx;break
    if siji_char is None: return "ì˜¤ë¥˜(ì‹œì§€íŒë‹¨ë¶ˆê°€)", "", ""
    dg_idx = GAN.index(day_gan_char); sidu_start_map = {0:0,5:0, 1:2,6:2, 2:4,7:4, 3:6,8:6, 4:8,9:8}
    start_gan_idx_for_ja_hour = sidu_start_map.get(dg_idx)
    if start_gan_idx_for_ja_hour is None: return "ì˜¤ë¥˜(ì¼ê°„â†’ì‹œê°„ë§µ)", "", ""
    time_gan_idx = (start_gan_idx_for_ja_hour + siji_order_idx) % 10
    return GAN[time_gan_idx] + siji_char, GAN[time_gan_idx], siji_char

def get_daewoon(year_gan_char, gender, birth_dt, month_gan_char, month_ji_char, solar_data_dict):
    is_yang_year = GAN.index(year_gan_char) % 2 == 0
    is_sunhaeng = (is_yang_year and gender=="ë‚¨ì„±") or (not is_yang_year and gender=="ì—¬ì„±")
    saju_year_for_daewoon = get_saju_year(birth_dt, solar_data_dict)
    relevant_terms_for_daewoon = []
    for yr_offset in [-1, 0, 1]:
        year_terms = solar_data_dict.get(saju_year_for_daewoon + yr_offset, {})
        for term_name, term_dt in year_terms.items():
            if term_name in SAJU_MONTH_TERMS_ORDER: relevant_terms_for_daewoon.append({'name':term_name,'datetime':term_dt})
    relevant_terms_for_daewoon.sort(key=lambda x: x['datetime'])
    if not relevant_terms_for_daewoon: return ["ì˜¤ë¥˜(ëŒ€ìš´ì ˆê¸°ë¶€ì¡±)"],0,is_sunhaeng
    target_term_dt = None
    if is_sunhaeng:
        for term_info in relevant_terms_for_daewoon:
            if term_info['datetime'] > birth_dt: target_term_dt=term_info['datetime'];break
    else:
        for term_info in reversed(relevant_terms_for_daewoon):
            if term_info['datetime'] < birth_dt: target_term_dt=term_info['datetime'];break
    if target_term_dt is None: return ["ì˜¤ë¥˜(ëŒ€ìš´ëª©í‘œì ˆê¸°ì—†ìŒ)"],0,is_sunhaeng
    days_difference = (target_term_dt - birth_dt if is_sunhaeng else birth_dt - target_term_dt).total_seconds()/(24*3600)
    daewoon_start_age = max(1, int(round(days_difference / 3)))
    month_ganji_str = month_gan_char + month_ji_char; current_month_gapja_idx = -1
    for i in range(60):
        if get_ganji_from_index(i) == month_ganji_str: current_month_gapja_idx=i;break
    if current_month_gapja_idx == -1: return ["ì˜¤ë¥˜(ì›”ì£¼ê°‘ìë³€í™˜ì‹¤íŒ¨)"],daewoon_start_age,is_sunhaeng
    daewoon_list_output = []
    for i in range(10):
        age_display = daewoon_start_age + i * 10
        next_gapja_idx = (current_month_gapja_idx+(i+1) if is_sunhaeng else current_month_gapja_idx-(i+1)+60)%60
        daewoon_list_output.append(f"{age_display}ì„¸: {get_ganji_from_index(next_gapja_idx)}")
    return daewoon_list_output, daewoon_start_age, is_sunhaeng

def get_seun_list(start_year, n=10): return [(y, get_year_ganji(y)[0]) for y in range(start_year, start_year+n)]
def get_wolun_list(base_year, base_month, solar_data_dict, n=12):
    output_wolun = []
    for i in range(n):
        current_year=base_year+(base_month-1+i)//12; current_month_num=(base_month-1+i)%12+1
        seun_gan_char=get_year_ganji(current_year)[1]
        dummy_birth_dt_for_wolun=datetime(current_year,current_month_num,15,12,0)
        wolun_ganji,_,_=get_month_ganji(seun_gan_char,dummy_birth_dt_for_wolun,solar_data_dict)
        output_wolun.append((f"{current_year}-{current_month_num:02d}", wolun_ganji))
    return output_wolun
def get_ilun_list(year_val, month_val, day_val, n=10):
    base_dt = datetime(year_val, month_val, day_val); output_ilun = []
    for i in range(n):
        current_dt = base_dt + timedelta(days=i)
        ilun_ganji,_,_ = get_day_ganji(current_dt.year, current_dt.month, current_dt.day)
        output_ilun.append((current_dt.strftime("%Y-%m-%d"), ilun_ganji))
    return output_ilun

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(layout="wide", page_title="ğŸ”® ì¢…í•© ì‚¬ì£¼ ëª…ì‹ ê³„ì‚°ê¸°")
st.title("ğŸ”® ì¢…í•© ì‚¬ì£¼ ëª…ì‹ ë° ìš´ì„¸ ê³„ì‚°ê¸°")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'saju_calculated_once' not in st.session_state:
    st.session_state.saju_calculated_once = False
if 'interpretation_segments' not in st.session_state:
    st.session_state.interpretation_segments = []


st.sidebar.header("1. ì¶œìƒ ì •ë³´")
calendar_type = st.sidebar.radio("ë‹¬ë ¥ ìœ í˜•", ("ì–‘ë ¥", "ìŒë ¥"), index=0, horizontal=True)
is_leap_month = False
if calendar_type == "ìŒë ¥": is_leap_month = st.sidebar.checkbox("ìœ¤ë‹¬", help="ìŒë ¥ ìƒì¼ì´ ìœ¤ë‹¬ì¸ ê²½ìš° ì²´í¬í•´ì£¼ì„¸ìš”.")

current_year_for_input = datetime.now().year
min_input_year = min(solar_data.keys()) if solar_data else 1900
max_input_year = max(solar_data.keys()) if solar_data else 2100

by = st.sidebar.number_input("ì¶œìƒ ì—°ë„", min_input_year, max_input_year, 1990, help=f"{calendar_type} {min_input_year}~{max_input_year}ë…„")
bm = st.sidebar.number_input("ì¶œìƒ ì›”", 1, 12, 6)
bd = st.sidebar.number_input("ì¶œìƒ ì¼", 1, 31, 15)
bh = st.sidebar.number_input("ì¶œìƒ ì‹œ", 0, 23, 12)
bmin = st.sidebar.number_input("ì¶œìƒ ë¶„", 0, 59, 30)
gender = st.sidebar.radio("ì„±ë³„", ("ë‚¨ì„±","ì—¬ì„±"), horizontal=True, index=0)

st.sidebar.header("2. ìš´ì„¸ ê¸°ì¤€ì¼ (ì–‘ë ¥)")
today = datetime.now()
ty = st.sidebar.number_input("ê¸°ì¤€ ì—°ë„ ", min_input_year, max_input_year + 10, today.year, help=f"ì–‘ë ¥ ê¸°ì¤€ë…„ë„ ({min_input_year}~{max_input_year+10} ë²”ìœ„)")
tm = st.sidebar.number_input("ê¸°ì¤€ ì›”  " , 1, 12, today.month)
td = st.sidebar.number_input("ê¸°ì¤€ ì¼  " , 1, 31, today.day)

if st.sidebar.button("ğŸ§® ê³„ì‚° ì‹¤í–‰", use_container_width=True, type="primary"):
    st.session_state.interpretation_segments = [] # ê³„ì‚° ì‹œë§ˆë‹¤ ì´ˆê¸°í™”
    st.session_state.saju_calculated_once = True

    birth_dt_input_valid = True; birth_dt = None
    if calendar_type == "ì–‘ë ¥":
        try: birth_dt = datetime(by,bm,bd,bh,bmin)
        except ValueError: st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì–‘ë ¥ ë‚ ì§œ/ì‹œê°„ì…ë‹ˆë‹¤."); birth_dt_input_valid = False; st.stop()
    else: # ìŒë ¥
        try:
            lunar_conv_date = LunarDate(by, bm, bd, is_leap_month)
            solar_equiv_date = lunar_conv_date.toSolarDate()
            birth_dt = datetime(solar_equiv_date.year, solar_equiv_date.month, solar_equiv_date.day, bh, bmin)
            st.sidebar.info(f"ìŒë ¥ {by}ë…„ {bm}ì›” {bd}ì¼{' (ìœ¤ë‹¬)' if is_leap_month else ''}ì€ ì–‘ë ¥ {birth_dt.strftime('%Y-%m-%d')} ì…ë‹ˆë‹¤.")
        except ValueError as e: st.error(f"âŒ ìŒë ¥ ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜: {e}."); birth_dt_input_valid = False; st.stop()
        except Exception as e: st.error(f"âŒ ìŒë ¥ ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}"); birth_dt_input_valid = False; st.stop()

    if birth_dt_input_valid and birth_dt:
        saju_year_val = get_saju_year(birth_dt, solar_data)
        year_pillar_str, year_gan_char, year_ji_char = get_year_ganji(saju_year_val)
        month_pillar_str, month_gan_char, month_ji_char = get_month_ganji(year_gan_char, birth_dt, solar_data)
        day_pillar_str, day_gan_char, day_ji_char = get_day_ganji(birth_dt.year, birth_dt.month, birth_dt.day)
        time_pillar_str, time_gan_char, time_ji_char = get_time_ganji(day_gan_char, birth_dt.hour, birth_dt.minute)

        st.subheader("ğŸ“œ ì‚¬ì£¼ ëª…ì‹")
        ms_data = {
            "êµ¬ë¶„":["ì²œê°„","ì§€ì§€","ê°„ì§€"],
            "ì‹œì£¼":[time_gan_char if "ì˜¤ë¥˜" not in time_pillar_str else "?", time_ji_char if "ì˜¤ë¥˜" not in time_pillar_str else "?", time_pillar_str if "ì˜¤ë¥˜" not in time_pillar_str else "ì˜¤ë¥˜"],
            "ì¼ì£¼":[day_gan_char if "ì˜¤ë¥˜" not in day_pillar_str else "?", day_ji_char if "ì˜¤ë¥˜" not in day_pillar_str else "?", day_pillar_str if "ì˜¤ë¥˜" not in day_pillar_str else "ì˜¤ë¥˜"],
            "ì›”ì£¼":[month_gan_char if "ì˜¤ë¥˜" not in month_pillar_str else "?", month_ji_char if "ì˜¤ë¥˜" not in month_pillar_str else "?", month_pillar_str if "ì˜¤ë¥˜" not in month_pillar_str else "ì˜¤ë¥˜"],
            "ì—°ì£¼":[year_gan_char if "ì˜¤ë¥˜" not in year_pillar_str else "?", year_ji_char if "ì˜¤ë¥˜" not in year_pillar_str else "?", year_pillar_str if "ì˜¤ë¥˜" not in year_pillar_str else "ì˜¤ë¥˜"]
        }
        ms_df = pd.DataFrame(ms_data).set_index("êµ¬ë¶„")
        st.table(ms_df)
        saju_year_caption = f"ì‚¬ì£¼ ê¸°ì¤€ ì—°ë„ (ì…ì¶˜ ê¸°ì¤€): {saju_year_val}ë…„"
        st.caption(saju_year_caption)
        st.session_state.interpretation_segments.append(("ğŸ“œ ì‚¬ì£¼ ëª…ì‹", ms_df.to_markdown() + "\n" + saju_year_caption))


        saju_8char_for_analysis = {
            "year_gan": year_gan_char, "year_ji": year_ji_char, "month_gan": month_gan_char, "month_ji": month_ji_char,
            "day_gan": day_gan_char, "day_ji": day_ji_char, "time_gan": time_gan_char, "time_ji": time_ji_char
        }
        analysis_possible = all(val_char and len(val_char) == 1 and ((key.endswith("_gan") and val_char in GAN) or (key.endswith("_ji") and val_char in JI)) for key, val_char in saju_8char_for_analysis.items())
        
        ohaeng_strengths, sipshin_strengths = {}, {}
        if analysis_possible:
            try: ohaeng_strengths, sipshin_strengths = calculate_ohaeng_sipshin_strengths(saju_8char_for_analysis)
            except Exception as e: st.warning(f"ì˜¤í–‰/ì‹­ì‹  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}"); analysis_possible = False
        else: st.warning("ì‚¬ì£¼ ê¸°ë‘¥ ì˜¤ë¥˜ë¡œ ì˜¤í–‰/ì‹­ì‹  ë¶„ì„ ë¶ˆê°€.")

        st.markdown("---"); st.subheader("ğŸŒ³ğŸ”¥ ì˜¤í–‰(äº”è¡Œ) ë¶„ì„")
        if ohaeng_strengths and analysis_possible:
            ohaeng_df_for_chart = pd.DataFrame.from_dict(ohaeng_strengths, orient='index', columns=['ì„¸ë ¥']).reindex(OHENG_ORDER)
            st.bar_chart(ohaeng_df_for_chart, height=300)
            ohaeng_summary_exp_text_html = get_ohaeng_summary_explanation(ohaeng_strengths)
            st.markdown(f"<div style='font-size: 0.95rem; ...'>{ohaeng_summary_exp_text_html}</div>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
            st.session_state.interpretation_segments.append(("ğŸŒ³ğŸ”¥ ì˜¤í–‰(äº”è¡Œ) ë¶„ì„", strip_html_tags(ohaeng_summary_exp_text_html)))
            ohaeng_table_data = {"ì˜¤í–‰": OHENG_ORDER, "ì„¸ë ¥": [ohaeng_strengths.get(o, 0.0) for o in OHENG_ORDER]}
            st.session_state.interpretation_segments.append(("ì˜¤í–‰ ì„¸ë ¥í‘œ", pd.DataFrame(ohaeng_table_data).to_markdown(index=False)))

        st.markdown("---"); st.subheader("ğŸŒŸ ì‹­ì‹ (åç¥) ë¶„ì„")
        if sipshin_strengths and analysis_possible:
            sipshin_df_for_chart = pd.DataFrame.from_dict(sipshin_strengths, orient='index', columns=['ì„¸ë ¥']).reindex(SIPSHIN_ORDER)
            st.bar_chart(sipshin_df_for_chart, height=400)
            sipshin_summary_exp_text_html = get_sipshin_summary_explanation(sipshin_strengths, day_gan_char)
            st.markdown(f"<div style='font-size: 0.95rem; ...'>{sipshin_summary_exp_text_html}</div>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
            st.session_state.interpretation_segments.append(("ğŸŒŸ ì‹­ì‹ (åç¥) ë¶„ì„", strip_html_tags(sipshin_summary_exp_text_html)))
            sipshin_table_data = {"ì‹­ì‹ ": SIPSHIN_ORDER, "ì„¸ë ¥": [sipshin_strengths.get(s, 0.0) for s in SIPSHIN_ORDER]}
            st.session_state.interpretation_segments.append(("ì‹­ì‹  ì„¸ë ¥í‘œ", pd.DataFrame(sipshin_table_data).to_markdown(index=False)))


        st.markdown("---"); st.subheader("ğŸ’ª ì¼ê°„ ê°•ì•½ ë° ê²©êµ­(æ ¼å±€) ë¶„ì„")
        shinkang_status_result, shinkang_explanation_html = "ë¶„ì„ ì •ë³´ ì—†ìŒ", ""
        gekuk_name_result, gekuk_explanation_html = "ë¶„ì„ ì •ë³´ ì—†ìŒ", ""
        if analysis_possible and ohaeng_strengths and sipshin_strengths:
            try:
                shinkang_status_result = determine_shinkang_shinyak(sipshin_strengths)
                shinkang_explanation_html = get_shinkang_explanation(shinkang_status_result)
                gekuk_name_result = determine_gekuk(day_gan_char, month_gan_char, month_ji_char, sipshin_strengths)
                gekuk_explanation_html = get_gekuk_explanation(gekuk_name_result)
            except Exception as e: st.warning(f"ì‹ ê°•/ê²©êµ­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        col_shinkang, col_gekuk = st.columns(2)
        with col_shinkang: st.markdown(f"""<div style="..."><h4>ì¼ê°„ ê°•ì•½</h4><p>{shinkang_status_result}</p><p>{shinkang_explanation_html}</p></div>""", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
        with col_gekuk: st.markdown(f"""<div style="..."><h4>ê²©êµ­ ë¶„ì„</h4><p>{gekuk_name_result}</p><p>{gekuk_explanation_html}</p></div>""", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
        st.session_state.interpretation_segments.append(("ğŸ’ª ì¼ê°„ ê°•ì•½", f"**{shinkang_status_result}**\n{strip_html_tags(shinkang_explanation_html)}"))
        st.session_state.interpretation_segments.append(("ğŸ’ª ê²©êµ­(æ ¼å±€) ë¶„ì„", f"**{gekuk_name_result}**\n{strip_html_tags(gekuk_explanation_html)}"))

        st.markdown("---"); st.subheader("ğŸ¤ğŸ’¥ í•©ì¶©í˜•í•´íŒŒ ë¶„ì„")
        if analysis_possible and day_gan_char:
            try:
                hap_chung_results_dict = analyze_hap_chung_interactions(saju_8char_for_analysis)
                hap_chung_text_parts = []
                if any(v for v in hap_chung_results_dict.values()):
                    output_html_parts = []
                    for interaction_type, found_list in hap_chung_results_dict.items():
                        if found_list:
                            output_html_parts.append(f"<h6 style='...'>{interaction_type}</h6>") # ìŠ¤íƒ€ì¼ ìƒëµ
                            items_html = "".join([f"<li style='...'>{item}</li>" for item in found_list]) # ìŠ¤íƒ€ì¼ ìƒëµ
                            output_html_parts.append(f"<ul style='...'>{items_html}</ul>") # ìŠ¤íƒ€ì¼ ìƒëµ
                            hap_chung_text_parts.append(f"**{interaction_type}**\n" + "\n".join([f"- {item}" for item in found_list]))
                    st.markdown("".join(output_html_parts), unsafe_allow_html=True)
                    hap_chung_explanation_html_val = get_hap_chung_detail_explanation(hap_chung_results_dict)
                    st.markdown(f"<div style='...'>{hap_chung_explanation_html_val}</div>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
                    hap_chung_text_parts.append(f"\n**ì„¤ëª…:**\n{strip_html_tags(hap_chung_explanation_html_val)}")
                else: 
                    no_hapchung_msg = "íŠ¹ë³„íˆ ë‘ë“œëŸ¬ì§€ëŠ” í•©ì¶©í˜•í•´íŒŒì˜ ê´€ê³„ê°€ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                    st.markdown(f"<p>{no_hapchung_msg}</p>", unsafe_allow_html=True)
                    hap_chung_text_parts.append(no_hapchung_msg)
                st.session_state.interpretation_segments.append(("ğŸ¤ğŸ’¥ í•©ì¶©í˜•í•´íŒŒ ë¶„ì„", "\n\n".join(hap_chung_text_parts)))
            except Exception as e: st.warning(f"í•©ì¶©í˜•í•´íŒŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        
        st.markdown("---"); st.subheader("ğŸ”® ì£¼ìš” ì‹ ì‚´(ç¥ç…) ë¶„ì„")
        if analysis_possible and day_gan_char:
            try:
                found_shinsals_list = analyze_shinsal(saju_8char_for_analysis)
                shinsal_text_parts = []
                if found_shinsals_list:
                    items_html = "".join([f"<li style='...'>{item}</li>" for item in found_shinsals_list]) # ìŠ¤íƒ€ì¼ ìƒëµ
                    st.markdown(f"<h6>ë°œê²¬ëœ ì£¼ìš” ì‹ ì‚´:</h6><ul style='...'>{items_html}</ul>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
                    shinsal_explanation_html_val = get_shinsal_detail_explanation(found_shinsals_list)
                    st.markdown(f"<div style='...'>{shinsal_explanation_html_val}</div>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
                    shinsal_text_parts.append("**ë°œê²¬ëœ ì£¼ìš” ì‹ ì‚´:**\n" + "\n".join([f"- {item}" for item in found_shinsals_list]))
                    shinsal_text_parts.append(f"\n**ì„¤ëª…:**\n{strip_html_tags(shinsal_explanation_html_val)}")
                else:
                    no_shinsal_msg = "íŠ¹ë³„íˆ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ìš” ì‹ ì‚´ì´ ì—†ìŠµë‹ˆë‹¤."
                    st.markdown(f"<p>{no_shinsal_msg}</p>", unsafe_allow_html=True)
                    shinsal_text_parts.append(no_shinsal_msg)
                st.session_state.interpretation_segments.append(("ğŸ”® ì£¼ìš” ì‹ ì‚´(ç¥ç…) ë¶„ì„", "\n\n".join(shinsal_text_parts)))
            except Exception as e: st.warning(f"ì‹ ì‚´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

        st.markdown("---"); st.subheader("â˜¯ï¸ ìš©ì‹ (å–œç¥) ë° ê¸°ì‹ (å¿Œç¥) ë¶„ì„ (ê°„ëµ)")
        if analysis_possible and shinkang_status_result not in ["ë¶„ì„ ì •ë³´ ì—†ìŒ", "ë¶„ì„ ì˜¤ë¥˜"] and day_gan_char:
            try:
                yongshin_gishin_info = determine_yongshin_gishin_simplified(day_gan_char, shinkang_status_result)
                st.markdown(yongshin_gishin_info["html"], unsafe_allow_html=True)
                gaewoon_tips_html_content = get_gaewoon_tips_html(yongshin_gishin_info["yongshin"])
                if gaewoon_tips_html_content: st.markdown(f"<div style='...'>{gaewoon_tips_html_content}</div>", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ
                
                yongshin_text = strip_html_tags(yongshin_gishin_info["html"])
                gaewoon_text = strip_html_tags(gaewoon_tips_html_content) if gaewoon_tips_html_content else ""
                st.session_state.interpretation_segments.append(("â˜¯ï¸ ìš©ì‹ (å–œç¥) ë° ê¸°ì‹ (å¿Œç¥) ë¶„ì„ (ê°„ëµ)", yongshin_text + ("\n\n" + gaewoon_text if gaewoon_text else "")))

            except Exception as e: st.warning(f"ìš©ì‹ /ê¸°ì‹  ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        st.markdown("""<div style="..."><strong >ì°¸ê³  ì‚¬í•­:</strong><br>...</div>""", unsafe_allow_html=True) # ìŠ¤íƒ€ì¼ ìƒëµ, ë‚´ìš©ì€ ì´ì „ê³¼ ë™ì¼
        st.session_state.interpretation_segments.append(("ìš©ì‹ /ê¸°ì‹  ì°¸ê³ ì‚¬í•­", strip_html_tags("""<div><strong>ì°¸ê³  ì‚¬í•­:</strong><br> ì—¬ê¸°ì„œ ì œê³µë˜ëŠ” ìš©ì‹ (å–œç¥) ë° ê¸°ì‹ (å¿Œç¥) ì •ë³´ëŠ” ì‚¬ì£¼ ë‹¹ì‚¬ìì˜ ì‹ ê°•/ì‹ ì•½ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ <strong>ê°„ëµí™”ëœ ì–µë¶€ìš©ì‹ (æŠ‘æ‰¶ç”¨ç¥) ê²°ê³¼</strong>ì…ë‹ˆë‹¤. ì‹¤ì œ ì •ë°€í•œ ìš©ì‹  íŒë‹¨ì€ ì‚¬ì£¼ ì „ì²´ì˜ ì¡°í›„(èª¿å€™ - ê³„ì ˆì˜ ì¡°í™”), í†µê´€(é€šé—œ - ë§‰íŒ ê¸°ìš´ ì†Œí†µ), ë³‘ì•½(ç—…è—¥ - ì‚¬ì£¼ì˜ ë¬¸ì œì ê³¼ í•´ê²°ì±…) ë“± ë‹¤ì–‘í•œ ìš”ì†Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•˜ë¯€ë¡œ, ë³¸ ê²°ê³¼ëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©í•˜ì‹œê³  ì¤‘ìš”í•œ íŒë‹¨ì€ ë°˜ë“œì‹œ ì‚¬ì£¼ ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.</div>""")))


        st.markdown("---"); st.subheader(f"é‹ ëŒ€ìš´ ({gender})")
        daewoon_text_for_copy = []
        if "ì˜¤ë¥˜" in month_pillar_str or not month_gan_char or not month_ji_char :
            st.warning("ì›”ì£¼ ì˜¤ë¥˜ë¡œ ëŒ€ìš´ í‘œì‹œ ë¶ˆê°€.")
            daewoon_text_for_copy.append("ì›”ì£¼ ì˜¤ë¥˜ë¡œ ëŒ€ìš´ í‘œì‹œ ë¶ˆê°€.")
        else:
            daewoon_text_list, daewoon_start_age_val, is_sunhaeng_val = get_daewoon(year_gan_char, gender, birth_dt, month_gan_char, month_ji_char, solar_data)
            if isinstance(daewoon_text_list, list) and daewoon_text_list and "ì˜¤ë¥˜" in daewoon_text_list[0]:
                st.warning(daewoon_text_list[0])
                daewoon_text_for_copy.append(daewoon_text_list[0])
            elif isinstance(daewoon_text_list, list) and all(":" in item for item in daewoon_text_list):
                daewoon_start_info = f"ëŒ€ìš´ ì‹œì‘ ë‚˜ì´: ì•½ {daewoon_start_age_val}ì„¸ ({'ìˆœí–‰' if is_sunhaeng_val else 'ì—­í–‰'})"
                st.text(daewoon_start_info)
                daewoon_table_data = {"ì£¼ê¸°(ë‚˜ì´)": [item.split(':')[0] for item in daewoon_text_list], "ê°„ì§€": [item.split(': ')[1] for item in daewoon_text_list]}
                daewoon_df = pd.DataFrame(daewoon_table_data)
                st.table(daewoon_df)
                daewoon_text_for_copy.append(daewoon_start_info)
                daewoon_text_for_copy.append(daewoon_df.to_markdown(index=False))
            else: 
                st.warning("ëŒ€ìš´ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨.")
                daewoon_text_for_copy.append("ëŒ€ìš´ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨.")
        st.session_state.interpretation_segments.append((f"é‹ ëŒ€ìš´ ({gender})", "\n".join(daewoon_text_for_copy)))


        st.markdown("---"); st.subheader(f"ğŸ“… ê¸°ì¤€ì¼({ty}ë…„ {tm}ì›” {td}ì¼) ìš´ì„¸")
        unse_text_for_copy = []
        col1,col2 = st.columns(2)
        with col1:
            st.markdown(f"##### æ­² ì„¸ìš´ ({ty}ë…„~)")
            seun_df = pd.DataFrame(get_seun_list(ty,5), columns=["ì—°ë„","ê°„ì§€"])
            st.table(seun_df)
            unse_text_for_copy.append(f"**æ­² ì„¸ìš´ ({ty}ë…„~)**\n{seun_df.to_markdown(index=False)}")

            st.markdown(f"##### æ—¥ ì¼ìš´ ({ty}-{tm:02d}-{td:02d}~)")
            ilun_df = pd.DataFrame(get_ilun_list(ty,tm,td,7), columns=["ë‚ ì§œ","ê°„ì§€"])
            st.table(ilun_df)
            unse_text_for_copy.append(f"\n**æ—¥ ì¼ìš´ ({ty}-{tm:02d}-{td:02d}~)**\n{ilun_df.to_markdown(index=False)}")
        with col2:
            st.markdown(f"##### æœˆ ì›”ìš´ ({ty}ë…„ {tm:02d}ì›”~)")
            wolun_df = pd.DataFrame(get_wolun_list(ty,tm,solar_data,12), columns=["ì—°ì›”","ê°„ì§€"])
            st.table(wolun_df)
            unse_text_for_copy.append(f"\n**æœˆ ì›”ìš´ ({ty}ë…„ {tm:02d}ì›”~)**\n{wolun_df.to_markdown(index=False)}")
        st.session_state.interpretation_segments.append((f"ğŸ“… ê¸°ì¤€ì¼({ty}ë…„ {tm}ì›” {td}ì¼) ìš´ì„¸", "\n".join(unse_text_for_copy)))


# --- "í’€ì´ ë‚´ìš© ì§€ì¹¨ìœ¼ë¡œ ë³´ê¸°" ë²„íŠ¼ ë° ê²°ê³¼ í‘œì‹œ ---
if st.session_state.saju_calculated_once:
    st.markdown("---")
    if st.button("ğŸ“‹ í’€ì´ ë‚´ìš© ì§€ì¹¨ìœ¼ë¡œ ë³´ê¸°", use_container_width=True):
        st.session_state.show_interpretation_guide = True # ë²„íŠ¼ í´ë¦­ ì‹œ í‘œì‹œ í”Œë˜ê·¸

    if st.session_state.get('show_interpretation_guide', False): # ë²„íŠ¼ì´ í´ë¦­ë˜ì—ˆì„ ë•Œë§Œ ì‹¤í–‰
        with st.expander("ğŸ“– ì „ì²´ í’€ì´ ë‚´ìš© (í…ìŠ¤íŠ¸ ì§€ì¹¨)", expanded=True):
            if st.session_state.interpretation_segments:
                full_text_guide = ""
                for title, content in st.session_state.interpretation_segments:
                    full_text_guide += f"## {title}\n\n{content}\n\n---\n\n"
                
                st.markdown(full_text_guide)
                st.info("ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì—¬ í™œìš©í•˜ì„¸ìš”.")
            else:
                st.markdown("í‘œì‹œí•  í’€ì´ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ê³„ì‚° ì‹¤í–‰'ì„ í•´ì£¼ì„¸ìš”.")
        # ê°€ì´ë“œ í‘œì‹œ í›„ì—ëŠ” ë‹¤ì‹œ ìˆ¨ê¸°ë„ë¡ í”Œë˜ê·¸ë¥¼ ì´ˆê¸°í™” í•  ìˆ˜ ìˆìŒ (ì„ íƒì )
        # st.session_state.show_interpretation_guide = False 
else:
    st.info("ì¶œìƒ ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  'ê³„ì‚° ì‹¤í–‰' ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì‚¬ì£¼ ëª…ì‹ê³¼ í’€ì´ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
